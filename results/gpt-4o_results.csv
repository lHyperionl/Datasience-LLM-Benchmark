task_id,difficulty,category,dataset_reference,generated_code,evaluation_score,evaluation_details,model_config,evaluator_config
E1,easy,Exploratory Data Analysis (EDA),winequality-red.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('winequality-red.csv')

# 1) List all column names and identify data types
print(""Column Names and Data Types:"")
print(df.dtypes)
print()

# 2) Descriptive statistics for numerical columns
numeric_cols = df.select_dtypes(include=['number']).columns

print(""Descriptive Statistics for Numerical Columns:"")
for col in numeric_cols:
    print(f""--- {col} ---"")
    print(f""Mean: {df[col].mean()}"")
    print(f""Median: {df[col].median()}...",6,"The code addresses most requirements but misses key aspects. 1) **Correctness**: It correctly loads the dataset, calculates descriptive stats, and reports dimensions. However, it fails to explicitly identify data types (numerical/categorical) as required in step 1, only printing raw dtypes. Step 4's categorical/ordinal identification uses a heuristic (unique value count) instead of proper type checks, missing the 'quality' column's ordinal nature. 2) **Code Quality**: Clean structure and proper imports, but lacks error handling for missing files (though the task assumes the CSV exists). 3) **Completeness**: Fails to explicitly classify columns as numerical/categorical, and the descriptive stats are manually calculated instead of using `describe()`, which is less efficient. The categorical identification logic is also less accurate than the ground truth's type-based approach. Improvements would include explicit type classification and using built-in methods for statistics.",gpt_4o,LLM_judge_config
E10,easy,Exploratory Data Analysis (EDA),video_games_sales.csv,"```python
import pandas as pd

# 1. Load the dataset and display the first 10 rows
df = pd.read_csv('video_games_sales.csv')
print(""First 10 rows of the dataset:"")
print(df.head(10))

# 2. Show the shape of the dataset (rows and columns)
print(""\nShape of the dataset:"")
print(df.shape)

# 3. List all column names and their data types
print(""\nColumn names and data types:"")
print(df.dtypes)

# 4. Display the top 10 games by Global_Sales
print(""\nTop 10 games by Global_Sales:"")
print(df.sort_value...",7,"The generated code correctly addresses all seven requirements with proper structure and concise implementation. It successfully loads the dataset, displays the first 10 rows, shows the shape, lists column details, sorts by Global_Sales, shows unique values, calculates summary statistics, and identifies missing values. However, it lacks critical error handling (e.g., FileNotFoundError for missing files, column existence checks) that the ground truth includes, which could cause runtime errors in edge cases. Additionally, while the generated code uses `df.dtypes` instead of `df.info()` for column information, both technically fulfill the requirement. To improve, adding basic error checks would make the code more robust, and including column existence validations would align it more closely with the ground truth's reliability. The code is clean and functional but misses some safety measures.",gpt_4o,LLM_judge_config
E11,easy,Data Cleaning and Preprocessing,video_games_sales.csv,"```python
import pandas as pd
import numpy as np

# 1. Load the dataset
df = pd.read_csv('video_games_sales.csv')

# 2. Handle missing values in the Year column by filling them with the median year
median_year = df['Year'].median()
df['Year'] = df['Year'].fillna(median_year)

# 3. Remove games with missing Publisher information
df = df.dropna(subset=['Publisher'])

# 4. Create a new column 'Years_Since_Release' using 2023 as the current year
df['Years_Since_Release'] = 2023 - df['Year'].astype(i...",6,"The generated code addresses most tasks but has critical omissions. It fails to handle non-numeric 'Year' and 'Global_Sales' columns, which could cause errors. It also skips converting 'Year' to integer type after filling missing values and doesn't ensure 'Years_Since_Release' is non-negative. While it correctly removes duplicates, filters sales, and displays results, the lack of data type conversions and error handling reduces robustness. Adding type conversions (e.g., pd.to_numeric) and handling edge cases (like negative years) would improve correctness and completeness.",gpt_4o,LLM_judge_config
E12,easy,Data Visualization,video_games_sales.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('video_games_sales.csv')

# Handle missing values if necessary
df = df.dropna(subset=['Platform', 'Genre', 'Global_Sales', 'NA_Sales', 'EU_Sales', 'Year'])

# 1) Bar chart showing top 10 gaming platforms by total global sales
platform_sales = df.groupby('Platform')['Global_Sales'].sum().sort_values(ascending=False).head(10)
plt.figure(figsize=(10,6))
platform_sales.plot(kind='bar', color='skyblue')...",6,"The generated code addresses most of the required visualizations but has critical issues. 1) It uses incorrect column names like 'Year' instead of 'Year_of_Release', which would cause errors if the actual dataset uses the latter. 2) The pie chart lacks genre thresholding (filtering out small categories), making it less readable. 3) The line plot does not include the year range filtering (1980-2020) present in the ground truth. While the code structure is clean and includes proper labels/titles, these discrepancies in column handling and data preprocessing reduce its correctness and completeness. Adding proper column validation and genre filtering would improve alignment with the task requirements.",gpt_4o,LLM_judge_config
E13,easy,Exploratory Data Analysis (EDA),diabetes.csv,"```python
# Imports
import pandas as pd
import numpy as np

# 1. Load the dataset and display the first 10 rows
df = pd.read_csv('diabetes.csv')
print(""First 10 rows:"")
print(df.head(10))

# 2. Show the shape of the dataset (rows and columns)
print(""\nShape of the dataset:"")
print(df.shape)

# 3. List all column names and their data types
print(""\nColumn names and data types:"")
print(df.dtypes)

# 4. Calculate the percentage of diabetic vs non-diabetic patients (Outcome column)
print(""\nPercenta...",6,"The generated code addresses most of the task requirements but has several critical issues. 1) Correctness: It misses error handling for file loading, doesn't check if 'Outcome' column exists before using it, and incorrectly checks all columns for zeros instead of the specific ones mentioned in the ground truth. 2) Code quality: Lacks structured organization, proper error handling, and clear separation of sections. 3) Completeness: Fails to implement the specified columns for zero-value checks, doesn't show zero values as a percentage of the dataset, and omits detailed messages for no missing values. The code is functional but lacks robustness and specific implementation details from the ground truth.",gpt_4o,LLM_judge_config
E14,easy,Data Cleaning and Preprocessing,diabetes.csv,"```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

# Step 1: Load the dataset
df = pd.read_csv('diabetes.csv')

# Step 2: Identify columns with zero values that are invalid
invalid_zero_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

# Step 3: Replace zero values in these columns with NaN
df[invalid_zero_cols] = df[invalid_zero_cols].replace(0, np.nan)

# Step 4: Fill missing values with the median of each column
df[invalid_...",8,"The generated code correctly performs the main tasks: loading the dataset, replacing zeros with NaN, filling with medians, removing duplicates, creating the BMI category, and scaling numerical features. However, it lacks robustness in handling edge cases. For example, it doesn’t check if the specified columns exist before replacing zeros or filling missing values, which could cause errors if the dataset is missing any of these columns. Similarly, it doesn’t verify the presence of the 'Outcome' column before removing it during scaling, risking a ValueError. While the code is concise and functional for a standard dataset, adding these checks would improve reliability and align more closely with the ground truth’s attention to detail. The output formatting is also slightly less informative than the ground truth’s, but the core requirements are met.",gpt_4o,LLM_judge_config
E15,easy,Data Visualization,diabetes.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
data = pd.read_csv('diabetes.csv')

# Set Seaborn style
sns.set(style=""whitegrid"")

# 1. Correlation heatmap
plt.figure(figsize=(10,8))
corr = data.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt="".2f"")
plt.title('Correlation Heatmap')
plt.tight_layout()
plt.show()

# 2. Histograms for all numerical features
data.hist(figsize=(12, 10), bins=20, edgecolor='black')
plt.suptitle('Distributi...",7,"The generated code addresses most of the required visualizations but misses some key details. It lacks error handling for file loading, which is present in the ground truth. The histograms use a single figure title instead of individual subplot titles, and the box plots have less descriptive labels (e.g., ""Diabetes Outcome (0: Non-Diabetic, 1: Diabetic)"" is missing). The pair plot excludes 'Outcome' as a variable, only using it as the hue, whereas the ground truth includes it in the feature set. The pie chart lacks exploded slices and shadows. While the code is functional, these omissions reduce completeness and adherence to the formatting requirements. Improvements in label precision, error handling, and pair plot configuration would elevate the score.",gpt_4o,LLM_judge_config
E16,easy,Exploratory Data Analysis (EDA),world-happiness-report-2021.csv,"```python
import pandas as pd

# 1) Load the dataset and display the first 10 rows
df = pd.read_csv('world-happiness-report-2021.csv')
print(""First 10 rows:"")
print(df.head(10))

# 2) Show the shape of the dataset (rows and columns)
print(""\nShape of the dataset:"")
print(df.shape)

# 3) List all column names and their data types
print(""\nColumn names and data types:"")
print(df.dtypes)

# 4) Display the unique regional indicators and count of countries per region
print(""\nUnique Regional Indicato...",7,"The generated code correctly performs the core tasks of loading the dataset, displaying the first 10 rows, shape, dtypes, regional counts, top 10 countries, summary statistics, and missing values. However, it lacks critical error handling for missing columns (e.g., checking if 'Regional indicator' or 'Ladder score' exists before accessing them), which could cause runtime errors if the actual column names differ slightly from the assumptions. It also uses `df.dtypes` instead of `df.info()` for task 3, which provides less comprehensive information (e.g., missing non-null counts). Additionally, the code does not include a `try-except` block for file loading, though the task assumes the CSV is present. While the code is functionally correct, improving robustness by adding column existence checks and using `df.info()` would better align with best practices and ensure reliability.",gpt_4o,LLM_judge_config
E17,easy,Data Cleaning and Preprocessing,world-happiness-report-2021.csv,"```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Load dataset
df = pd.read_csv('world-happiness-report-2021.csv')

# Handle missing values
for column in df.columns:
    if df[column].dtype == 'object':
        df[column].fillna(df[column].mode()[0], inplace=True)
    else:
        df[column].fillna(df[column].mean(), inplace=True)

# Create 'Happiness_Category'
def happiness_category(score):
    if score > 6.5:
        return 'Hig...",7,"The generated code addresses most requirements but has two critical issues. First, it incorrectly standardizes the 'Regional indicator' after label encoding, whereas the task specifies to encode it without scaling. Second, it lacks error handling for missing files, which the ground truth includes. While the code handles missing values, creates derived features, removes outliers, and displays data info, the misapplication of scaling to a categorical feature and absence of try-except blocks reduce its correctness and completeness. Code quality is good, but minor improvements like checking for missing values before filling and ensuring 'Regional indicator' is excluded from scaling would enhance it.",gpt_4o,LLM_judge_config
E18,easy,Data Visualization,world-happiness-report-2021.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

# Load dataset
df = pd.read_csv('world-happiness-report-2021.csv')

# Rename columns for easier access
df.rename(columns={
    'Ladder score': 'Happiness Score',
    'Logged GDP per capita': 'GDP per Capita',
    'Social support': 'Social Support',
    'Healthy life expectancy': 'Life Expectancy',
    'Freedom to make life choices': 'Freedom',
    'Ge...",7,"The generated code addresses most of the task requirements but has critical issues in the radar chart and some missing elements. The world map, bar chart, heatmap, scatter plots, and box plot are implemented correctly with proper labels and formatting. However, the radar chart lacks normalization of data (MinMaxScaler) used in the ground truth, leading to potential misrepresentation of features with different scales. Additionally, the radar chart in the generated code uses Plotly's Scatterpolar without the same level of customization (e.g., angle calculation, filled areas) as the ground truth. The code also omits error handling for file loading, which the ground truth includes. Minor discrepancies in column names (e.g., ""Life Expectancy"" vs. ""Healthy Life Expectancy"") could cause issues if the dataset's actual column names differ. These gaps prevent it from fully meeting the completeness and correctness criteria.",gpt_4o,LLM_judge_config
E19,easy,Exploratory Data Analysis (EDA),synthetic_covid19_data.csv,"```python
import pandas as pd

# 1) Load the dataset and parse the 'date' column as datetime
df = pd.read_csv('synthetic_covid19_data.csv', parse_dates=['date'])

# 2) Display the first 10 rows
print(df.head(10))

# 3) Show the shape of the dataset
print(""Shape of the dataset:"", df.shape)

# 4) List all column names and their data types
print(""Column names and data types:"")
print(df.dtypes)

# 5) Calculate and display the total sum of 'total_cases' and 'total_deaths' grouped by 'continent'
group...",7,"The generated code addresses most task requirements but lacks critical error handling and data validation. It does not check for the existence of required columns in steps 5-7, risking KeyErrors if columns are missing. For step 5, it fails to handle NaN values in 'continent', which could produce incorrect groupings. Step 7 ignores non-numeric values in 'new_cases' and 'new_deaths', potentially causing calculation errors. While the code structure is clean and meets basic functionality, it misses robustness features like try-except blocks, column validation, and data type coercion present in the ground truth. The approach for step 6 is logically sound but could be more explicit about ensuring date sorting within each location. These omissions reduce reliability and completeness.",gpt_4o,LLM_judge_config
E2,easy,Exploratory Data Analysis (EDA),winequality-red.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv('winequality-red.csv')

# 1. Calculate and report the average (mean) 'quality' of the red wines
mean_quality = df['quality'].mean()
print(f""Average wine quality: {mean_quality:.2f}"")

# 2. Group by 'quality' and calculate average 'alcohol'
alcohol_by_quality = df.groupby('quality')['alcohol'].mean().reset_index()

# 3. Create a bar chart
plt.figure(figsize=(8, 6))
sns.barplot(x='q...",7,"The generated code correctly calculates the average quality and average alcohol content by quality group, and creates a bar chart as required. However, it lacks the print statement for the second part (average alcohol by quality group), which the ground truth explicitly includes. The chart is basic but functional, missing optional details like data labels on bars and font size adjustments. The code assumes the file exists without error handling, which is acceptable per the task's assumption but not as robust as the ground truth. These gaps reduce completeness and code quality slightly.",gpt_4o,LLM_judge_config
E20,easy,Data Cleaning and Preprocessing,synthetic_covid19_data.csv,"```python
import pandas as pd
import numpy as np

# Load dataset and parse 'date' as datetime
df = pd.read_csv('synthetic_covid19_data.csv', parse_dates=['date'])

# Fill missing values
df['hosp_patients'] = df['hosp_patients'].fillna(0)
df['icu_patients'] = df['icu_patients'].fillna(0)

for col in ['positive_rate', 'reproduction_rate']:
    if col in df.columns:
        df[col] = df[col].fillna(df[col].mean())

# Create 'mortality_rate' column and handle division by zero
df['mortality_rate'] = ...",7,"The generated code addresses most requirements but has notable gaps. It correctly loads the data, handles missing values, creates the required columns, filters by 2021, and displays results. However, it lacks critical steps: 1) It doesn't convert columns like 'total_deaths', 'total_cases', 'people_fully_vaccinated', and 'population' to numeric before calculations, risking errors if these columns are non-numeric. 2) It omits error handling for missing files, which the ground truth includes. 3) It doesn't use `.copy()` when filtering, which could lead to `SettingWithCopyWarning` warnings. While the code works under ideal conditions, these omissions reduce robustness. Improving column type validation and adding error handling would strengthen it.",gpt_4o,LLM_judge_config
E21,easy,Data Visualization,synthetic_covid19_data.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset and parse 'date' column
df = pd.read_csv('synthetic_covid19_data.csv', parse_dates=['date'])

# Set seaborn style
sns.set(style='whitegrid')

# 1) Time series line plot of 'new_cases' for 'India'
india_df = df[df['location'] == 'India']
plt.figure(figsize=(12, 6))
sns.lineplot(data=india_df, x='date', y='new_cases')
plt.title('Daily New COVID-19 Cases in India')
plt.xlabel('Date')
plt.ylabel('New ...",6,"The generated code addresses the main visualization tasks but has critical omissions. 1) The time series plot for India does not sort the data by date, which could lead to incorrect temporal ordering. 2) The bar chart for total_deaths by continent fails to use the latest entry for each location before summing, potentially aggregating outdated data. 3) The box plot for stringency_index does not handle missing values in the 'continent' or 'stringency_index' columns, which could cause plotting errors. While the code structure is clean and uses the required libraries, it lacks proper data preparation steps for some visualizations (e.g., sorting, deduplication, NA handling) that were explicitly in the ground truth. Additionally, the scatter plot omits the population size parameter as shown in the ground truth, though this wasn't strictly required by the task.",gpt_4o,LLM_judge_config
E22,easy,Exploratory Data Analysis (EDA),clash_royale_cards.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# 1) List all column names and data types
print(""Column names and data types:"")
print(df.dtypes)
print()

# 2) Descriptive statistics for specified numerical columns
numerical_cols = ['elixirCost', 'Win Rate', 'Usage']

for col in numerical_cols:
    print(f""Descriptive statistics for '{col}':"")
    print(f""Mean: {df[col].mean()}"")
    print(f""Median: {df[col].median()}"")
    print(f""Standard Deviation:...",7,"The generated code correctly loads the dataset, lists column data types, calculates descriptive statistics for the specified numerical columns, and reports the total number of rows. However, it lacks error handling for potential issues like missing files or columns, which the ground truth code includes. Additionally, the code does not explicitly list column names before printing their data types, as the task requires. The descriptive statistics are computed accurately but in a less structured format compared to the ground truth's use of `agg()`. Improving error handling and aligning with the output structure would enhance robustness and completeness.",gpt_4o,LLM_judge_config
E23,easy,Data Manipulation,clash_royale_cards.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# Filter cards with elixirCost <= 3
filtered_df = df[df['elixirCost'] <= 3]

# Select 'Card' and 'Win Rate' columns
selected_df = filtered_df[['Card', 'Win Rate']]

# Sort by 'Win Rate' in descending order
sorted_df = selected_df.sort_values(by='Win Rate', ascending=False)

# Display the result
print(sorted_df)
```",7,"The generated code correctly loads the CSV, filters by `elixirCost <= 3`, selects the required columns, and sorts by `Win Rate` in descending order, satisfying the task's core functionality. However, it lacks error handling for file loading (e.g., `FileNotFoundError`), which is present in the ground truth. It also does not check if the required columns (`Card` and `Win Rate`) exist in the dataset before selection, which could lead to a `KeyError` if the column names differ slightly (e.g., typos or case variations). While the code is concise and meets the minimum requirements, adding robustness through error handling and column validation would improve its quality and completeness.",gpt_4o,LLM_judge_config
E24,easy,Data Visualization,clash_royale_cards.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# Set style for seaborn
sns.set(style=""whitegrid"")

# Create histogram for elixirCost
plt.figure(figsize=(8, 6))
sns.histplot(df['elixirCost'], bins=range(int(df['elixirCost'].min()), int(df['elixirCost'].max()) + 2), kde=False)

# Add title and labels
plt.title('Distribution of Elixir Cost')
plt.xlabel('Elixir Cost')
plt.ylabel('Number of Cards')

#...",7,"The generated code correctly loads the CSV file and creates a histogram for the `elixirCost` column using seaborn, with appropriate labels and a title. It includes proper imports and uses `sns.set()` for styling. However, it lacks error handling for file loading (e.g., `FileNotFoundError`), which is critical for robustness. Additionally, it does not verify the existence of the `elixirCost` column, risking a KeyError. The x-axis ticks are not explicitly set to integers, and the title is less descriptive than the ground truth. These omissions reduce completeness and correctness, but the core functionality is implemented effectively.",gpt_4o,LLM_judge_config
E25,easy,Exploratory Data Analysis (EDA),iris.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv(""iris.csv"")

# 1) List all column names and identify data types
print(""Column Names and Data Types:"")
print(df.dtypes)
print()

# 2) Descriptive statistics for numerical columns
numerical_cols = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
print(""Descriptive Statistics:"")
for col in numerical_cols:
    print(f""\nStatistics for {col}:"")
    print(f""Mean: {df[col].mean()}"")
    print(f""Median: {df[col].median(...",7,"The generated code correctly loads the dataset, lists column names and data types, calculates descriptive statistics for the numerical columns, and reports species counts. However, it lacks error handling for file loading (e.g., FileNotFoundError) and does not verify if the required columns exist in the DataFrame, which could cause runtime errors if the dataset structure differs. Additionally, the output formatting is less structured compared to the ground truth code. These omissions reduce robustness and completeness, though the core functionality aligns with the task requirements.",gpt_4o,LLM_judge_config
E26,easy,Data Manipulation,iris.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('iris.csv')

# Filter records where Species is 'Iris-setosa'
filtered_df = df[df['Species'] == 'Iris-setosa']

# Select and display only SepalLengthCm and SepalWidthCm columns
result = filtered_df[['SepalLengthCm', 'SepalWidthCm']]
print(result)
```",10,"The generated code is correct, high-quality, and complete. It properly loads the CSV file, filters for 'Iris-setosa' using boolean indexing, selects the required columns, and prints the result. The code includes necessary imports, uses clear variable names, and follows the task requirements precisely. The absence of error handling is not critical here since the task didn't specify it as a requirement, and the code directly addresses all specified steps without unnecessary complexity.",gpt_4o,LLM_judge_config
E27,easy,Data Visualization,iris.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('iris.csv')

# Create a color map for species
species = df['Species'].unique()
colors = {'Iris-setosa': 'red', 'Iris-versicolor': 'green', 'Iris-virginica': 'blue'}

# Plot
plt.figure(figsize=(8, 6))
for sp in species:
    subset = df[df['Species'] == sp]
    plt.scatter(subset['SepalLengthCm'], subset['SepalWidthCm'], 
                color=colors[sp], label=sp)

plt.title('Sepal Length vs Sepal W...",9,"The generated code correctly loads the iris.csv dataset, creates a scatter plot of SepalLengthCm vs SepalWidthCm, and colors points by the Species column. It includes proper imports, a title, and axis labels. The code is concise and meets all the task requirements. The main differences from the ground truth are the hard-coded color mapping for species (instead of dynamically assigning colors) and slightly different axis label formatting (""Sepal Length (cm)"" vs ""SepalLengthCm""), but these are acceptable variations. The code lacks error handling, but the task explicitly states to assume the CSV file exists, so this isn't critical. The structure is simple and effective, with no major issues.",gpt_4o,LLM_judge_config
E28,easy,Exploratory Data Analysis (EDA),heart.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('heart.csv')

# 1) List all column names and identify the data type of each column
print(""Column Names and Data Types:"")
print(df.dtypes)
print()

# 2) Descriptive statistics for numerical columns
numerical_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR']
for col in numerical_cols:
    print(f""Statistics for {col}:"")
    print(f""  Mean: {df[col].mean()}"")
    print(f""  Median: {df[col].median()}"")
    print(f""  Standard Deviat...",7,"The generated code correctly loads the dataset, lists column names and data types, calculates descriptive statistics for the specified numerical columns, and reports value counts for 'HeartDisease'. However, it lacks error handling for missing files (e.g., FileNotFoundError) and does not check if the required columns exist in the DataFrame, which could lead to runtime errors. Additionally, while the code fulfills the task requirements, it misses the structured formatting and detailed output (e.g., explicit column name listing) seen in the ground truth. These omissions reduce robustness and completeness, but the core functionality is correct. To improve, add error handling and column existence checks.",gpt_4o,LLM_judge_config
E29,easy,Data Manipulation,heart.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('heart.csv')

# Filter the dataset
filtered_df = df[(df['Age'] > 50) & (df['HeartDisease'] == 1)]

# Select and display specific columns
result = filtered_df[['Age', 'Sex', 'ChestPainType', 'Cholesterol']]
print(result)
```",10,"The generated code fully meets the task requirements. It correctly loads the dataset, filters for Age > 50 and HeartDisease == 1, and selects the specified columns. It includes proper imports and assumes the CSV is in the current directory as instructed. The code is concise, effective, and directly addresses all the specified steps without unnecessary complexity. While it lacks error handling and function structure present in the ground truth, those were not explicitly required by the task. The solution is correct, complete, and of high quality.",gpt_4o,LLM_judge_config
E3,easy,Data Filtering,winequality-red.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('winequality-red.csv')

# Filter wines with alcohol > 12 and pH < 3.3
filtered_df = df[(df['alcohol'] > 12) & (df['pH'] < 3.3)]

# Find the wine with the highest quality in the filtered set
top_quality_wine = filtered_df[filtered_df['quality'] == filtered_df['quality'].max()]

# Display all features of the wine with the highest quality
print(top_quality_wine)
```",7,"The generated code correctly filters the dataset using compound conditions and identifies the wine with the highest quality score. However, it lacks error handling for edge cases (e.g., missing file, invalid columns) and does not explicitly check if the filtered subset is empty, which could lead to errors if no rows meet the criteria. Additionally, while it displays the wine's features, it does not use `.to_string()` to ensure all columns are shown without truncation, unlike the ground truth. The code is functional but less robust and structured compared to the ground truth solution.",gpt_4o,LLM_judge_config
E30,easy,Data Visualization,heart.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv('heart.csv')

# Histogram for Age
plt.figure(figsize=(8,6))
sns.histplot(df['Age'], bins=20, kde=False, color='skyblue')
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

# Bar chart for Sex
plt.figure(figsize=(6,5))
sex_counts = df['Sex'].value_counts()
sns.barplot(x=sex_counts.index, y=sex_counts.values, palette='pastel')
p...",7,"The generated code correctly loads the dataset and creates both required plots with titles and labeled axes, demonstrating good code structure and proper use of seaborn. However, it lacks explicit handling of the 'Sex' column's encoding (assuming 0/1 instead of 'M'/'F'), which the ground truth code addresses by mapping values. Additionally, the code omits error handling (try/except blocks) for file loading or missing columns, which is a critical part of the evaluation criteria. While the plots are functional, the absence of descriptive labels for 'Sex' and error resilience reduces completeness. Improving these aspects would enhance clarity and robustness.",gpt_4o,LLM_judge_config
E31,easy,Exploratory Data Analysis (EDA),spotify_2023.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('spotify_2023.csv')

# 1) List all column names and identify data types
print(""Column Names and Data Types:"")
print(df.dtypes)
print(""\n"")

# 2) Convert 'streams' to numeric, coercing errors to NaN, then report NaNs
df['streams'] = pd.to_numeric(df['streams'], errors='coerce')
print(""Number of NaN values in 'streams' column after conversion:"")
print(df['streams'].isna().sum())
print(""\n"")

# 3) Calculate descriptive statistics fo...",7,"The generated code correctly loads the dataset, converts the 'streams' column to numeric with error coercion, calculates descriptive statistics for the specified numerical columns, and counts unique artists. However, it lacks error handling for missing files (e.g., FileNotFoundError), does not check if the required columns exist in the dataframe (which could cause KeyErrors), and omits reporting the original data types of columns (as done in the ground truth). Additionally, it does not handle the case where 'artist(s)_name' might be missing. These omissions reduce robustness and completeness. Improving by adding column existence checks, error handling, and explicit data type reporting would bring it closer to the ground truth's thoroughness.",gpt_4o,LLM_judge_config
E32,easy,Data Manipulation,spotify_2023.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('spotify_2023.csv')

# Ensure 'streams' is numeric, coerce errors to NaN
df['streams'] = pd.to_numeric(df['streams'], errors='coerce')

# Filter for songs released in 2023
df_2023 = df[df['released_year'] == 2023]

# Select relevant columns
filtered_df = df_2023[['track_name', 'artist(s)_name', 'streams']]

# Sort by streams in descending order
sorted_df = filtered_df.sort_values(by='streams', ascending=False)

# Display the resu...",10,"The generated code is correct, high-quality, and complete. It successfully loads the dataset, converts the 'streams' column to numeric with error coercion, filters for 2023 releases, selects the required columns, sorts by streams in descending order, and displays the result. The code is concise, uses proper imports, and follows best practices. While it lacks error handling for file loading (which the task assumes the file exists), this is not required by the problem statement. The code meets all specified requirements without unnecessary complexity.",gpt_4o,LLM_judge_config
E33,easy,Data Visualization,spotify_2023.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('spotify_2023.csv')

# Histogram for 'bpm'
plt.figure(figsize=(8, 5))
plt.hist(df['bpm'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of BPM')
plt.xlabel('Beats Per Minute (BPM)')
plt.ylabel('Frequency')
plt.grid(True)
plt.tight_layout()
plt.show()

# Scatter plot for 'danceability_%' vs 'energy_%'
plt.figure(figsize=(8, 5))
plt.scatter(df['danceability_%'], df['energy_%'],...",10,"The generated code fully satisfies the task requirements. It correctly loads the CSV file, creates a histogram for the 'bpm' column with appropriate labels and title, and generates a scatter plot for 'danceability_%' vs 'energy_%' with proper axis labels and a title. The code has clean structure, proper imports, and includes necessary visualization parameters like grid lines and figure sizing. While it lacks error handling (which wasn't explicitly required by the task), it meets all specified criteria with concise and effective implementation. The code is well-organized and produces the required visualizations without unnecessary complexity.",gpt_4o,LLM_judge_config
E34,easy,Exploratory Data Analysis (EDA),youtube_trendings.csv,"```python
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# 1) List all column names and their inferred data types
print(""Column Names and Data Types:"")
print(df.dtypes)

# 2) Clean 'Video views', 'Likes', and 'Dislikes' columns
numeric_cols = ['Video views', 'Likes', 'Dislikes']
for col in numeric_cols:
    df[col] = (
        df[col]
        .astype(str)
        .str.replace(',', '', regex=False)
    )
    df[col] = pd.to_numeric(df[col], e...",8,"The generated code correctly addresses the core requirements, including loading the dataset, cleaning the specified numeric columns, calculating descriptive statistics, filling missing values in the 'Category' column, and reporting unique counts. It uses efficient pandas operations and is concise. However, it lacks error handling for missing files (though the task assumes the file exists) and does not check for the existence of critical columns like 'Category' or the numeric columns, which could cause runtime errors if absent. Additionally, while it prints the required statistics, it does not format numbers with commas as in the ground truth, though this was not explicitly required. The code is clean and well-structured but could benefit from robustness checks and more detailed output for clarity.",gpt_4o,LLM_judge_config
E35,easy,Data Manipulation,youtube_trendings.csv,"```python
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# Clean 'Video views' column
df['Video views'] = pd.to_numeric(df['Video views'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)

# Filter videos with views > 50,000,000
filtered_df = df[df['Video views'] > 50000000]

# Select and display 'Video' and 'Video views' columns, sorted by 'Video views' descending
result = filtered_df[['Video', 'Video views']].sort_values(by='Vid...",10,"The generated code is fully correct, high-quality, and complete. It properly loads the CSV, cleans the 'Video views' column by removing commas, converting to numeric with error handling, filling NaNs with 0, filters for views > 50,000,000, selects the required columns, and sorts descending. The code is concise, uses efficient one-liners for transformations, and includes proper imports (though `numpy` is unused, which is a minor nitpick). All requirements are met without unnecessary complexity. The only minor omission is the error handling for missing files, but the task explicitly states to assume the CSV is present, so this is not critical. The solution is clean and directly addresses the task.",gpt_4o,LLM_judge_config
E36,easy,Data Visualization,youtube_trendings.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv('youtube_trendings.csv')

# Clean 'Likes' column
df['Likes'] = pd.to_numeric(df['Likes'].astype(str).str.replace(',', '', regex=False), errors='coerce').fillna(0)

# Clean 'Video views' column
df['Video views'] = pd.to_numeric(df['Video views'].astype(str).str.replace(',', '', regex=False), errors='coerce').fillna(0)

# Create scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(df['Video views'], df['...",9,"The generated code is mostly correct and meets the task requirements. It properly loads the CSV, cleans the 'Likes' and 'Video views' columns by removing commas, converting to numeric with error handling, and fills NaNs with 0. The scatter plot is created with appropriate labels, title, and styling. However, it lacks error handling for file loading (e.g., FileNotFoundError), which the ground truth code includes. Additionally, the code assumes the columns exist without validation, though the task explicitly states to assume the CSV is in the current directory. The code is concise and well-structured but could benefit from added robustness for edge cases. Strong points include correct data cleaning and plotting logic.",gpt_4o,LLM_judge_config
E37,easy,Exploratory Data Analysis (EDA),mobiles_2025.csv,"```python
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('mobiles_2025.csv')

# Clean 'Mobile Weight' column
df['Mobile Weight'] = pd.to_numeric(df['Mobile Weight'].str.replace('g', '', regex=False), errors='coerce')

# Clean 'RAM' column
df['RAM'] = pd.to_numeric(df['RAM'].str.replace('GB', '', regex=False), errors='coerce')

# Clean 'Battery Capacity' column
df['Battery Capacity'] = pd.to_numeric(df['Battery Capacity'].str.replace('mAh', '', regex=False), errors='c...",6,"The generated code correctly performs the core data cleaning tasks and calculates the required statistics, but it lacks critical error handling and structure. It doesn't include try-except blocks for file loading, which could cause crashes if the CSV is missing. It also fails to check if columns exist before processing, risking KeyErrors. While it prints the final data types and statistics, it omits the initial data types and dataset shape information required by the task. The descriptive statistics section uses `agg()` but doesn't replicate the exact format (e.g., '50%' for median) or handle cases where columns might not be numeric. Code quality is acceptable but could benefit from modular structure and more robust validation.",gpt_4o,LLM_judge_config
E38,easy,Data Manipulation,mobiles_2025.csv,"```python
import pandas as pd

# Load dataset
df = pd.read_csv('mobiles_2025.csv')

# Clean 'Launched Price (India)' column
df['Launched Price (India)'] = pd.to_numeric(
    df['Launched Price (India)']
        .str.replace('INR ', '', regex=False)
        .str.replace(',', '', regex=False),
    errors='coerce'
)

# Clean 'RAM' column
df['RAM'] = pd.to_numeric(
    df['RAM'].str.replace('GB', '', regex=False),
    errors='coerce'
)

# Filter data
filtered_df = df[
    (df['Company Name'] == 'App...",8,"The generated code correctly performs the core tasks of loading the dataset, cleaning the required columns, filtering, selecting, and sorting. It properly uses `pd.to_numeric` with `errors='coerce'` for robustness, and includes the necessary column transformations. However, it lacks error handling for file loading (e.g., `FileNotFoundError`), which is present in the ground truth. Additionally, it omits the `.copy()` when filtering to avoid `SettingWithCopyWarning` and does not explicitly convert columns to strings before string operations (though this might not be critical in practice). These omissions slightly reduce robustness and code quality, but the core functionality is correct.",gpt_4o,LLM_judge_config
E39,easy,Data Visualization,mobiles_2025.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('mobiles_2025.csv')

# Clean the 'RAM' column
df['RAM'] = pd.to_numeric(df['RAM'].str.replace('GB', '', regex=False), errors='coerce')

# Clean the 'Battery Capacity' column
df['Battery Capacity'] = pd.to_numeric(df['Battery Capacity'].str.replace('mAh', '', regex=False), errors='coerce')

# Set the plot style
sns.set(style=""whitegrid"")

# Create scatter plot
plt.figure(figsiz...",7,"The generated code correctly loads the dataset, cleans the `RAM` and `Battery Capacity` columns by removing unit suffixes and converting to numeric with error handling, and creates a scatter plot with appropriate coloring, title, and labels. However, it lacks robustness in the cleaning process by not explicitly converting the columns to strings before using `.str.replace()`, which could cause errors if non-string values exist. Additionally, it overwrites the original columns instead of creating new cleaned columns (as in the ground truth), which might be less ideal for preserving raw data. The code also omits the grid (though the task didn’t explicitly require it), but the absence of the string conversion step is a critical oversight that could lead to runtime failures. With minor adjustments to ensure string-type handling, it would be nearly perfect.",gpt_4o,LLM_judge_config
E4,easy,Exploratory Data Analysis (EDA),titanic.csv,"```python
import pandas as pd

# 1) Load the dataset and display the first 5 rows
df = pd.read_csv('titanic.csv')
print(""First 5 rows of the dataset:"")
print(df.head())

# 2) Show the shape of the dataset (rows and columns)
print(""\nShape of the dataset:"")
print(df.shape)

# 3) List all column names and their data types
print(""\nColumn names and data types:"")
print(df.dtypes)

# 4) Calculate the survival rate (percentage of passengers who survived)
survival_rate = df['Survived'].mean() * 100
pri...",9,"The generated code correctly addresses all five requirements with proper imports and structure. It accurately loads the dataset, displays the first 5 rows, shows the shape, lists column data types (using `df.dtypes` instead of `df.info()` but still meeting the task's requirement), calculates the survival rate using `mean()` (valid alternative to sum), and identifies missing values. The code is concise and well-structured. The only minor omission is the lack of error handling for file loading, but the task explicitly states to assume the CSV is in the current directory, making this acceptable. The solution is correct, complete, and high-quality.",gpt_4o,LLM_judge_config
E40,easy,Exploratory Data Analysis (EDA),imdb_top_250.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# 1. List all column names and their data types
print(""Column Names and Data Types:"")
print(df.dtypes)
print()

# 2. Calculate and report basic descriptive statistics for Year, Rating, and Runtime
numerical_columns = ['Year', 'Rating', 'Runtime']

for column in numerical_columns:
    print(f""Statistics for {column}:"")
    print(f""  Mean: {df[column].mean()}"")
    print(f""  Median: {df[column].median()}"")
    ...",6,"The generated code addresses the core requirements by loading the dataset, listing column data types, calculating descriptive statistics for the specified numerical columns, and reporting the total number of movies. However, it lacks critical error handling (e.g., missing file handling) and assumes the 'Runtime' column is already numeric, which may not be the case (the ground truth code explicitly handles this). The code also does not check if the required columns exist in the dataset, which could lead to runtime errors. While the structure is clean and readable, the absence of robustness (e.g., handling non-numeric 'Runtime', missing columns, or file errors) limits its reliability. Using `df.describe()` would have been more efficient for generating statistics. To improve, add error handling, column existence checks, and handle potential data formatting issues like the 'Runtime' column.",gpt_4o,LLM_judge_config
E41,easy,Data Manipulation,imdb_top_250.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# Filter movies with Rating >= 9.0
filtered_df = df[df['Rating'] >= 9.0]

# Select Title and Rating columns and sort by Rating descending
result = filtered_df[['Title', 'Rating']].sort_values(by='Rating', ascending=False)

# Display the result
print(result)
```",10,"The generated code perfectly addresses all requirements. It correctly loads the CSV file, filters movies with a rating >=9.0, selects the Title and Rating columns, and sorts by Rating in descending order. The code is concise, uses proper imports, and follows good Python practices. The only difference from the ground truth is the absence of explicit error handling, but the task explicitly states to ""assume the CSV file is in the current directory,"" making error handling non-critical here. The solution is clean, efficient, and fully meets the evaluation criteria.",gpt_4o,LLM_judge_config
E42,easy,Data Visualization,imdb_top_250.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv('imdb_top_250.csv')

# Histogram of Rating
plt.figure(figsize=(8, 6))
sns.histplot(df['Rating'], bins=20, kde=True)
plt.title('Distribution of Movie Ratings')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

# Scatter plot of Runtime vs Rating
plt.figure(figsize=(8, 6))
sns.scatterplot(data=df, x='Runtime', y='Rating')
plt.title('Rating vs Runtime')
plt....",6,"The generated code correctly loads the dataset, creates a histogram for `Rating` with titles and labels, and a scatter plot for `Rating` vs. `Runtime`. However, it lacks critical preprocessing for the `Runtime` column, which may contain strings like ""120 min"" and requires extraction of numeric values. The ground truth code includes this step, while the generated code would fail or produce incorrect scatter plots if `Runtime` isn't already numeric. Additionally, the generated code omits error handling for missing columns or files, which the ground truth explicitly addresses. These omissions affect completeness and correctness, as the code assumes data is preprocessed, which may not be valid. Code quality is good, but improvements in handling edge cases and data cleaning would enhance reliability.",gpt_4o,LLM_judge_config
E43,easy,Exploratory Data Analysis (EDA),penguins.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('penguins.csv')

# 1) Report number of missing values for each column
missing_values = df.isna().sum()
print(""Missing values per column:"")
print(missing_values)
print()

# 2) Handle numerical columns
num_cols = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
df_num = df.dropna(subset=num_cols)

# Calculate and report descriptive statistics
print(""Descriptive statistics for numerical columns:"")
for col ...",7,"The generated code correctly loads the dataset, reports missing values, filters rows based on the specified numerical columns, and calculates descriptive statistics. However, it lacks error handling for potential file-loading issues (e.g., FileNotFoundError), which the ground truth code explicitly includes. Additionally, the code does not check if the filtered DataFrame (`df_num`) is empty before calculating statistics, which could lead to errors if all rows are dropped. The unique values count section uses the original DataFrame instead of the filtered one, which is correct per the task, but the code could benefit from more structured output formatting (e.g., section headers, conditional messages). Overall, it meets most requirements but misses some robustness and clarity elements.",gpt_4o,LLM_judge_config
E44,easy,Data Manipulation,penguins.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('penguins.csv')

# Filter for Adelie species on Torgersen island
filtered_df = df[(df['species'] == 'Adelie') & (df['island'] == 'Torgersen')]

# Select relevant columns
selected_df = filtered_df[['culmen_length_mm', 'culmen_depth_mm']]

# Drop rows with missing values
cleaned_df = selected_df.dropna()

# Display first 5 rows
print(cleaned_df.head())
```",10,"The generated code perfectly addresses all requirements. It correctly loads the dataset, filters for 'Adelie' species on 'Torgersen' island, selects the specified columns, drops rows with missing values in those columns (the dropna() method is sufficient since only those columns exist in the DataFrame at that point), and displays the first 5 rows. Proper imports are included, and the code is concise, readable, and follows the same logical structure as the ground truth. The code is complete, correct, and demonstrates excellent code quality.",gpt_4o,LLM_judge_config
E45,easy,Data Visualization,penguins.csv,"```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('penguins.csv')

# Drop rows where any of the required columns are missing
df = df.dropna(subset=['culmen_length_mm', 'culmen_depth_mm', 'species'])

# Create scatter plot
plt.figure(figsize=(8, 6))
sns.scatterplot(
    data=df,
    x='culmen_length_mm',
    y='culmen_depth_mm',
    hue='species',
    palette='deep'
)

# Add title and labels
plt.title('Culmen Length vs Depth b...",10,"The generated code correctly solves the task with high code quality and completeness. It properly loads the dataset, filters out missing values in the required columns, creates a scatter plot with species-colored points, and includes title/labels. The code is concise, uses appropriate imports, and meets all specified requirements. The absence of a function and error handling is not critical here since the task explicitly states to ""assume the CSV file is in the current directory"" and does not require robust error handling. The code is well-structured and directly addresses the problem without unnecessary complexity.",gpt_4o,LLM_judge_config
E46,easy,Data Cleaning,penguins.csv,"```python
import pandas as pd

# 1. Read the dataset
df = pd.read_csv('penguins.csv')

# 2. Fill NA values in 'culmen_length_mm' and 'culmen_depth_mm' with column means
df['culmen_length_mm'] = df['culmen_length_mm'].fillna(df['culmen_length_mm'].mean())
df['culmen_depth_mm'] = df['culmen_depth_mm'].fillna(df['culmen_depth_mm'].mean())

# 3. Calculate and print statistics
for col in ['culmen_length_mm', 'culmen_depth_mm']:
    mean = df[col].mean()
    median = df[col].median()
    std_dev = df[...",7,"The generated code correctly loads the dataset, fills NA values in the specified columns with their means, calculates the required statistics, and reports the dataset dimensions. However, it lacks error handling for missing files (e.g., FileNotFoundError) and does not check if the target columns exist in the dataset, which could lead to runtime errors. Additionally, the output formatting is less structured compared to the ground truth (e.g., no headers for sections like ""Statistics for Cleaned Numerical Columns""). While the core functionality is met, improvements in robustness (error handling) and output clarity would elevate the solution.",gpt_4o,LLM_judge_config
E47,easy,Data Visualization,penguins.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load the dataset
df = pd.read_csv('penguins.csv')

# 2. Drop rows where `flipper_length_mm` is NA
df = df.dropna(subset=['flipper_length_mm'])

# Set seaborn style for better aesthetics
sns.set(style='whitegrid')

# 3. Create a histogram of the `flipper_length_mm` column
plt.figure(figsize=(8, 6))
sns.histplot(df['flipper_length_mm'], bins=20, kde=False)
plt.title('Distribution of Flipper Length (mm)')
plt....",10,"The generated code correctly solves the task with proper imports, structure, and execution. It successfully loads the dataset, drops rows with NA in `flipper_length_mm`, creates a histogram with the required title and labels, and a bar chart for `island` counts. All requirements are met, and the code is concise and well-structured. The absence of error handling (which the task explicitly allows by assuming the CSV exists) does not affect correctness. The code is clean, efficient, and adheres strictly to the specified objectives.",gpt_4o,LLM_judge_config
E48,easy,Exploratory Data Analysis (EDA),penguins.csv,"```python
import pandas as pd

# 1) Load the dataset
df = pd.read_csv('penguins.csv')

# 2) Filter the data to include only penguins from the 'Torgersen' island
torgersen_penguins = df[df['island'] == 'Torgersen']

# 3) Count and print the number of penguins belonging to each species
species_counts = torgersen_penguins['species'].value_counts()
print(species_counts)
```",8,"The generated code correctly loads the dataset, filters for 'Torgersen' island, and counts species occurrences. It meets the core requirements of the task and is concise. However, it lacks error handling (e.g., for missing files or columns) and validation checks present in the ground truth code. While the task assumes the CSV exists, robust code should handle edge cases like missing columns or empty data. The generated code is functional but could improve by adding safeguards (e.g., checking column existence) to enhance reliability. The structure is clean, but additional comments or error messages would improve clarity.",gpt_4o,LLM_judge_config
E49,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

data = {
    ""EmployeeID"": [""E001"", ""E002"", ""E003"", ""E004"", ""E005"", ""E006"", ""E007"", ""E008""],
    ""Department"": [""Sales"", ""HR"", ""Tech"", ""Sales"", ""Tech"", ""HR"", ""Tech"", ""Sales""],
    ""PerformanceScore"": [4, 3, 5, 2, 4, 3, 5, 4],
    ""YearsExperience"": [5, 2, 8, 3, 6, 2, 10, 4],
    ""ProjectsCompleted"": [10, 5, 15, 4, 12, 6, 20, 8],
    ""TrainingHours"": [20, 40, 10, 50, 20, 30, 15, 25]
}

df = pd.DataFrame(data)

# 1) Print the shape of the DataFrame
print(df.shape)

#...",10,"The generated code is correct, well-structured, and fully addresses all requirements. It properly imports pandas, defines the DataFrame with the exact data as specified, and includes the two required operations: printing the shape and data types. The code is concise, avoids unnecessary elements, and aligns with the task's instructions. It meets the evaluation criteria perfectly without any missing components or errors. The absence of additional labels or separators is acceptable since the task explicitly states ""Provide only Python code"" and does not require formatted output descriptions. Strong points include clarity, efficiency, and precise execution of the task.",gpt_4o,LLM_judge_config
E5,easy,Data Visualization,titanic.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load the Titanic dataset
df = pd.read_csv('titanic.csv')

# 1. Bar chart: Count of survivors vs non-survivors
survival_counts = df['Survived'].value_counts().sort_index()
plt.figure(figsize=(6, 4))
plt.bar(['Did Not Survive', 'Survived'], survival_counts)
plt.title('Survival Counts')
plt.xlabel('Survival Status')
plt.ylabel('Number of Passengers')
plt.tight_layout()
plt.show()

# 2. Bar chart: Distribution of passenger classes (Pcl...",6,"The generated code addresses most requirements but has critical issues. 1) It fails to handle missing Age values properly (uses dropna() instead of filling with median/mean as in the ground truth). 2) The survival status labels use ""Did Not Survive"" instead of the more explicit ""Non-survivor"" from the ground truth. 3) Missing error handling for file loading (no try-except block). 4) Less detailed axis labels (e.g., ""Passenger Class"" vs ""Passenger Classes (Pclass)""). While the code structure is clean and creates all four required plots, the missing value handling for Age is a significant oversight that affects completeness. The code could be improved by adding explicit missing value handling and more precise labeling.",gpt_4o,LLM_judge_config
E50,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

# Create the DataFrame
data = {
    'StudentID': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008'],
    'Subject': ['Math', 'Science', 'Math', 'English', 'Science', 'Math', 'English', 'Science'],
    'Midterm_Score': [85, 92, 78, 88, 76, 95, 82, 89],
    'Final_Score': [90, 88, 82, 92, 80, 91, 85, 93],
    'Attendance_Rate': [0.95, 0.98, 0.85, 0.92, 0.80, 0.99, 0.88, 0.96]
}

df = pd.DataFrame(data)

# 1) Average Midterm Score
avg_midterm = df['Midte...",9,"The generated code correctly creates the DataFrame, calculates and prints the average midterm and final scores, and identifies the subject with the highest average final score. It uses proper pandas methods and formatting. However, it slightly deviates from the ground truth by not explicitly printing the highest average score value alongside the subject, which was included in the ground truth. While this isn't strictly required by the task, including it would make the output more informative. The code is concise, well-structured, and handles the core requirements effectively.",gpt_4o,LLM_judge_config
E51,easy,Time Series Analysis,,"```python
import pandas as pd

# Create the data
data = {
    'Date': pd.to_datetime([
        '2024-01-01', '2024-01-02', '2024-01-03', 
        '2024-01-04', '2024-01-05', '2024-01-08'
    ]),
    'Ticker': ['TECHCO'] * 6,
    'Open': [150.0, 152.5, 151.0, 153.0, 155.5, 154.0],
    'High': [153.0, 153.5, 154.0, 156.0, 157.0, 156.5],
    'Low': [149.5, 150.5, 150.0, 152.5, 154.5, 153.0],
    'Close': [152.0, 151.0, 153.5, 155.0, 154.5, 156.0],
    'Volume': [1000000, 1200000, 1100000, 1300000, ...",10,"The generated code fully meets all requirements with correct implementation. It properly creates the DataFrame with 'Date' as the index, calculates the 'Daily_Range' column accurately, identifies the date with the highest 'Close' price using idxmax(), and prints the complete DataFrame. The code structure is clean, uses appropriate pandas methods (like 'inplace=True' and vectorized operations), and includes necessary imports. The only minor difference from the ground truth is the use of .date() instead of .strftime('%Y-%m-%d') for date formatting, but this is still valid and produces the correct date value. The solution is concise, readable, and demonstrates strong understanding of pandas operations.",gpt_4o,LLM_judge_config
E52,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

# Create the DataFrame
data = {
    'OrderID': [101, 102, 103, 104, 105, 106, 107],
    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam', 'Mouse', 'Laptop'],
    'Category': ['Electronics'] * 7,
    'Quantity': [1, 2, 1, 1, 3, 1, 1],
    'Price_USD': [1200, 25, 75, 300, 50, 25, 1150],
    'CustomerID': ['CUST001', 'CUST002', 'CUST001', 'CUST003', 'CUST002', 'CUST004', 'CUST001']
}

df = pd.DataFrame(data)

# 1) Calculate total revenue for each transac...",10,"The generated code fully meets all requirements. It correctly creates the DataFrame with the specified data, including the 'Category' column using a concise approach. The 'Total_Revenue' column is properly calculated by multiplying 'Quantity' and 'Price_USD'. The best-selling product is accurately identified using `groupby` and `idxmax`, and the first 5 rows are printed with `df.head()`. The code is clean, uses proper imports, and is structured efficiently. All tasks are completed without errors or omissions, demonstrating strong correctness and completeness. The minor differences in print formatting (e.g., absence of explicit message for the head) do not affect functionality, as the task only required printing the rows.",gpt_4o,LLM_judge_config
E53,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

data = {
    ""UserID"": [""User1"", ""User2"", ""User3"", ""User4"", ""User5"", ""User6""],
    ""SessionDurationMinutes"": [15, 25, 10, 30, 22, 18],
    ""PagesViewed"": [5, 8, 3, 10, 7, 6],
    ""DeviceType"": [""Desktop"", ""Mobile"", ""Desktop"", ""Mobile"", ""Desktop"", ""Mobile""],
    ""Converted"": [True, False, False, True, True, False]
}

df = pd.DataFrame(data)

# 1) Calculate and print the average ""SessionDurationMinutes""
average_duration = df[""SessionDurationMinutes""].mean()
print(""Av...",10,"The generated code fully meets all requirements. It correctly defines the DataFrame with the specified data, calculates the average session duration using `.mean()`, and counts users by device type with `.value_counts()`. The code is concise, well-structured, and uses proper pandas syntax. While it lacks the optional separator line and specific formatting (e.g., `.2f`), the core tasks are executed accurately. The absence of explanatory comments is a minor trade-off but doesn't affect correctness or functionality. The code is robust, clear, and adheres to best practices.",gpt_4o,LLM_judge_config
E54,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

# Define the data
data = {
    ""Timestamp"": [""2025-05-24 10:00"", ""2025-05-24 10:05"", ""2025-05-24 10:10"", ""2025-05-24 10:15"", ""2025-05-24 10:00"", ""2025-05-24 10:05""],
    ""SensorID"": [""S1"", ""S1"", ""S1"", ""S1"", ""S2"", ""S2""],
    ""TemperatureCelsius"": [22.5, 22.7, 22.6, 22.8, 21.9, 22.0],
    ""HumidityPercent"": [55, 56, 55, 57, 60, 59],
    ""AirQualityIndex"": [30, 32, 31, 33, 25, 26]
}

# Create DataFrame
df = pd.DataFrame(data)

# Find and print the maximum temperature
...",10,"The generated code is correct, well-structured, and完全 addresses all requirements. It properly defines the DataFrame with the specified data, uses appropriate pandas methods (.max() and .min()) to calculate the required values, and includes clear print statements. The code quality is high with proper imports and variable naming. The only minor difference from the ground truth is the print formatting (simpler vs. f-string with units), but the task did not specify exact output formatting, only that the values should be printed. All critical aspects are covered.",gpt_4o,LLM_judge_config
E55,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

# Define the data
data = {
    ""PostID"": [""SM01"", ""SM02"", ""SM03"", ""SM04"", ""SM05""],
    ""Platform"": [""Instagram"", ""Twitter"", ""Facebook"", ""Instagram"", ""Twitter""],
    ""PostType"": [""Image"", ""Text"", ""Video"", ""Image"", ""Text""],
    ""Likes"": [150, 80, 300, 200, 90],
    ""Shares"": [20, 15, 50, 30, 10],
    ""Comments"": [10, 5, 25, 15, 8]
}

# Create the DataFrame
df = pd.DataFrame(data)

# 1) Print total number of Likes
total_likes = df[""Likes""].sum()
print(""Total Likes:"", ...",10,"The generated code perfectly solves the task. It correctly defines the DataFrame with all required columns and data, calculates the total likes using `.sum()`, and identifies the PostType with the highest average shares using `.groupby()` and `.idxmax()`. The code is concise, well-structured, and includes proper imports. It addresses all requirements without unnecessary elements, and the output format is valid. The minor differences in print statements (e.g., simpler formatting) do not affect correctness or functionality. Strong points include clarity, accuracy, and adherence to the evaluation criteria.",gpt_4o,LLM_judge_config
E56,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

# Define the data and create the DataFrame
data = {
    ""PatientID"": [""P001"", ""P002"", ""P003"", ""P004"", ""P005"", ""P006""],
    ""AdmissionDate"": pd.to_datetime([""2025-01-10"", ""2025-01-12"", ""2025-01-15"", ""2025-01-18"", ""2025-01-20"", ""2025-01-22""]),
    ""DischargeDate"": pd.to_datetime([""2025-01-15"", ""2025-01-16"", ""2025-01-22"", ""2025-01-25"", ""2025-01-24"", ""2025-01-28""]),
    ""Diagnosis"": [""Flu"", ""Cold"", ""Flu"", ""Injury"", ""Cold"", ""Flu""],
    ""Age"": [34, 56, 23, 45, 67, 30],
 ...",10,"The generated code is correct, clean, and fully addresses all requirements. It properly defines the DataFrame with accurate data and data types, calculates the average age using `df[""Age""].mean()`, and counts gender distribution with `value_counts()`. The code is concise, well-structured, and includes necessary imports. The only minor difference from the ground truth is the output formatting (no explicit rounding), but this does not affect correctness. The code is functionally identical to the ground truth and meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
E57,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

# Define the movie ratings DataFrame
data = {
    ""MovieID"": [""M01"", ""M02"", ""M03"", ""M04"", ""M05""],
    ""Title"": [""Inception"", ""The Dark Knight"", ""Pulp Fiction"", ""Forrest Gump"", ""The Matrix""],
    ""Genre"": [""Sci-Fi"", ""Action"", ""Crime"", ""Drama"", ""Sci-Fi""],
    ""Year"": [2010, 2008, 1994, 1994, 1999],
    ""Rating"": [8.8, 9.0, 8.9, 8.8, 8.7],
    ""Votes"": [2200000, 2500000, 1900000, 1800000, 1700000]
}
df = pd.DataFrame(data)

# 1) Print the Title of the movie with the h...",10,"The generated code is technically correct, complete, and well-structured. It properly defines the DataFrame with all required columns and data, correctly identifies the highest-rated movie using `idxmax()` (which works even if multiple movies share the same max rating), and calculates the average year using `mean()`. While the ground truth code includes additional edge-case handling (e.g., checking for empty DataFrames) and more verbose print statements, the generated code meets all explicit requirements of the task without unnecessary complexity. The code is concise, uses efficient pandas methods, and avoids potential pitfalls like hardcoded values. It adheres to best practices with proper imports and variable naming. The only minor difference is the lack of formatted output (e.g., `.2f` for the year), but the task did not explicitly demand this, making the solution fully compliant.",gpt_4o,LLM_judge_config
E58,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

data = {
    ""CarID"": [""C001"", ""C002"", ""C003"", ""C004"", ""C005"", ""C006""],
    ""Brand"": [""Toyota"", ""Honda"", ""Ford"", ""Toyota"", ""BMW"", ""Honda""],
    ""Model"": [""Camry"", ""Civic"", ""Focus"", ""Rav4"", ""X5"", ""Accord""],
    ""Year"": [2020, 2021, 2019, 2022, 2023, 2020],
    ""PriceUSD"": [25000, 22000, 18000, 30000, 60000, 24000],
    ""Mileage"": [30000, 20000, 45000, 15000, 5000, 35000]
}

df = pd.DataFrame(data)

# 1) Print the total number of cars
print(""Total number of cars:"", l...",10,"The generated code is correct, well-structured, and fully addresses all requirements. It properly defines the DataFrame with the specified data, calculates the total number of cars using `len(df)` (equivalent to `df.shape[0]`), and computes the average ""PriceUSD"" with `df[""PriceUSD""].mean()`. The code is concise, avoids unnecessary elements, and meets the evaluation criteria precisely. The only minor difference from the ground truth is the absence of explicit comments and currency formatting (e.g., dollar sign and decimal places), but these were not explicitly required by the task. The solution is efficient and follows best practices for code quality.",gpt_4o,LLM_judge_config
E59,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

data = {
    ""PokemonID"": [1, 2, 3, 4, 5, 6],
    ""Name"": [""Bulbasaur"", ""Ivysaur"", ""Venusaur"", ""Charmander"", ""Charmeleon"", ""Charizard""],
    ""Type1"": [""Grass"", ""Grass"", ""Grass"", ""Fire"", ""Fire"", ""Fire""],
    ""Type2"": [""Poison"", ""Poison"", ""Poison"", None, None, ""Flying""],
    ""HP"": [45, 60, 80, 39, 58, 78],
    ""Attack"": [49, 62, 82, 52, 64, 84],
    ""Defense"": [49, 63, 83, 43, 58, 78]
}

df = pd.DataFrame(data)

# 1) Print the name of the Pokemon with the highest HP
...",10,"The generated code is correct, concise, and fully addresses all requirements. It accurately defines the DataFrame with the specified data, correctly identifies the Pokemon with the highest HP (Venusaur) and lowest Defense (Charmander), and prints their names. The code is well-structured with proper imports and minimal, effective logic. The only difference from the ground truth is the absence of explanatory print statements, but the task did not require such annotations. The solution is efficient and meets all criteria perfectly.",gpt_4o,LLM_judge_config
E6,easy,Data Cleaning,titanic.csv,"```python
import pandas as pd
import numpy as np
import re

# 1) Load dataset
df = pd.read_csv('titanic.csv')

# 1) Identify columns with missing values
missing_values = df.isnull().sum()
print(""Missing values per column:\n"", missing_values[missing_values > 0])

# 2) Fill missing Age values with median age
df['Age'].fillna(df['Age'].median(), inplace=True)

# 3) Fill missing Embarked values with most frequent port
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# 4) Drop the Cabin...",7,"The generated code correctly addresses most task requirements but has notable gaps. It properly handles loading data, filling missing values, dropping columns, and creating the 'Title' column. However, it lacks error handling for file not found (missing try-except block), omits title standardization (e.g., collapsing rare titles like 'Lady' to 'Rare'), and doesn't include the optional missing value verification print statements. The 'Title' extraction uses a lambda but doesn't handle edge cases as robustly as the ground truth's function. Code structure is clean but could benefit from more explicit comments and error handling. These omissions reduce completeness and robustness compared to the ground truth.",gpt_4o,LLM_judge_config
E60,easy,Exploratory Data Analysis (EDA),,"```python
import pandas as pd

data = {
    ""BookID"": [""B001"", ""B002"", ""B003"", ""B004"", ""B005""],
    ""Title"": [""The Great Gatsby"", ""To Kill a Mockingbird"", ""1984"", ""Pride and Prejudice"", ""The Hobbit""],
    ""Author"": [""F. Scott Fitzgerald"", ""Harper Lee"", ""George Orwell"", ""Jane Austen"", ""J.R.R. Tolkien""],
    ""Genre"": [""Classic"", ""Classic"", ""Dystopian"", ""Romance"", ""Fantasy""],
    ""Stock"": [12, 8, 15, 7, 20],
    ""Price"": [10.99, 9.50, 12.00, 8.75, 15.25]
}

df = pd.DataFrame(data)

# 1) Print the ""...",10,"The generated code is fully correct, high-quality, and complete. It accurately defines the DataFrame with all required columns and data, correctly identifies the book with the highest price using `idxmax()` and retrieves its title, and calculates the total stock using `sum()`. The code is concise, follows proper Python and pandas conventions, and adheres strictly to the task requirements without unnecessary complexity. The absence of explanatory comments is acceptable since the task only required ""only Python code"" and the functionality is clear. No critical issues or missing elements are present.",gpt_4o,LLM_judge_config
E7,easy,Exploratory Data Analysis (EDA),water_potability.csv,"```python
import pandas as pd

# 1) Load the dataset and display the first 10 rows
df = pd.read_csv('water_potability.csv')
print(""First 10 rows:"")
print(df.head(10))

# 2) Show the shape of the dataset
print(""\nDataset shape (rows, columns):"")
print(df.shape)

# 3) List all column names and their data types
print(""\nColumn names and data types:"")
print(df.dtypes)

# 4) Calculate the percentage of potable vs non-potable water samples
print(""\nPercentage of potable vs non-potable water samples:"")...",7,"The generated code correctly performs the core tasks of loading the dataset, displaying the first 10 rows, shape, column data types, potability percentages, missing values, and summary statistics. However, it lacks error handling for file operations (e.g., if the CSV is missing) and does not check for the existence of the 'Potability' column before accessing it, which could cause runtime errors. Additionally, while it meets the technical requirements, it omits structured formatting (e.g., separation lines, clear headings) present in the ground truth code, reducing readability. The summary statistics section also doesn't explicitly restrict to numerical columns, though `describe()` inherently handles this. To improve, add exception handling and validation checks for critical steps like file existence and column presence.",gpt_4o,LLM_judge_config
E8,easy,Data Cleaning,water_potability.csv,"```python
import pandas as pd
import numpy as np

# 1. Load dataset
df = pd.read_csv('water_potability.csv')

# Summary before cleaning
missing_before = df.isnull().sum()
shape_before = df.shape

# 2. Fill missing values with mean for numerical columns
df_filled = df.copy()
for col in df_filled.columns:
    if df_filled[col].isnull().sum() > 0:
        df_filled[col].fillna(df_filled[col].mean(), inplace=True)

# 3. Remove duplicate rows
df_filled.drop_duplicates(inplace=True)

# 4. Verify reaso...",6,"The generated code addresses most task requirements but has notable gaps. It correctly loads the dataset, fills missing values with mean (though it doesn't restrict to numerical columns), removes duplicates, and validates ranges. However, it lacks proper error handling for file loading, doesn't explicitly identify columns with missing values before cleaning, and uses arbitrary range values without domain justification. The summary output is less detailed than the ground truth (e.g., no ""before/after"" shape comparisons in a structured format). Additionally, the code doesn't check for non-negative values in all relevant parameters and doesn't print clear messages about the cleaning steps taken. These issues reduce its completeness and correctness compared to the ground truth.",gpt_4o,LLM_judge_config
E9,easy,Data Visualization,water_potability.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv('water_potability.csv')

# Set Seaborn style
sns.set(style=""whitegrid"")

# 1. Bar chart: potable vs non-potable
plt.figure(figsize=(6, 4))
sns.countplot(x='Potability', data=df, palette='Set2')
plt.title('Distribution of Potable vs Non-Potable Water Samples')
plt.xlabel('Potability (0 = Non-Potable, 1 = Potable)')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

# 2. Histograms ...",8,"The generated code correctly creates all four required visualizations and includes proper imports and structure. It handles missing values in plots by using seaborn's built-in NaN handling (e.g., `dropna()` in histograms and `df.corr()` for the heatmap). However, it lacks explicit error handling for file loading (e.g., `FileNotFoundError`), which the ground truth includes. The correlation heatmap could mention handling missing values in comments, and some axis labels (e.g., ""pH"" vs ""pH Value"") are less descriptive than the ground truth. The code is concise and well-structured, but adding comments about missing value handling and slightly more detailed labels would improve completeness and clarity.",gpt_4o,LLM_judge_config
H1,hard,Feature Engineering,winequality-red.csv,"```python
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import RFE, SelectKBest, f_regression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load dataset
df = pd.read_csv('winequality-red.csv')

# Feature Engineering: Create 3 new features
df['sulfate_to_chloride_ratio'] = df['sulphates'] / (df['chlorides'] + 1e-6)
df['alcohol_density_product'] = df['alcohol'] * df...",7,"The generated code addresses feature engineering and applies two selection methods but lacks explicit comparison of the feature sets and proper importance score calculation. It creates three engineered features, which meets the first requirement. The RFE and SelectKBest implementations are correct, but the code does not retrain the model on selected features to obtain accurate importance scores (as in the ground truth). It also fails to explicitly compare the selected features (e.g., common/unique features) or structure the output as clearly. Missing handling of NaN/infinite values introduced during feature engineering and not demonstrating the full comparison analysis between methods reduces completeness. Code quality is good but could better align with the ground truth's detailed output formatting and error handling.",gpt_4o,LLM_judge_config
H10,hard,Advanced Machine Learning and Ensemble Methods,video_games_sales.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor, StackingRegressor
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean...",4,"The generated code has significant issues. 1) **Incorrect preprocessing**: Uses LabelEncoder for features (should use OneHotEncoder) and doesn't handle missing values systematically. 2) **Incomplete evaluation**: Only uses R² score in cross_val_score, missing MAE/MSE/RMSE calculations. 3) **No 5-fold cross-validation for ensembles**: Voting/stacking models are evaluated on test sets, not via cross-validation. 4) **Hyperparameter tuning flaw**: Only tunes Random Forest explicitly, not based on performance metrics, and doesn't properly integrate with preprocessing. 5) **Feature importance issues**: Uses raw X.columns after LabelEncoder instead of transformed feature names, leading to inaccurate plots. 6) **Residual plots**: Limited to test set instead of full dataset analysis. The code lacks the structured pipelines and comprehensive statistical evaluation required by the task.",gpt_4o,LLM_judge_config
H11,hard,Advanced Statistical Modeling and Time Series Analysis,video_games_sales.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import Ridge, Lasso, LinearRegression
from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model im...",3,"The generated code fails to correctly address most of the task requirements. 1) Incorrect column names (""Year"" vs ""Year_of_Release"") and improper data handling cause data errors. 2) ARIMA implementation uses fixed parameters instead of automated selection. 3) Seasonal decomposition uses period=1 which is invalid for yearly data. 4) Multivariate regression lacks proper interaction terms and categorical encoding. 5) Polynomial regression misses validation and proper regularization implementation. 6) Bayesian regression uses PyMC3 but lacks proper model specification and prediction interval calculation. 7) Change point detection uses fixed penalty instead of data-driven selection. 8) Survival analysis uses an arbitrary threshold instead of the correct longevity definition. 9) Confidence intervals are improperly implemented with summary_table. 10) Time series cross-validation lacks integration with all models and proper data handling. Critical components like proper data aggregation, interaction term specification, and comprehensive model validation are missing.",gpt_4o,LLM_judge_config
H12,hard,Advanced Clustering and Market Segmentation,video_games_sales.csv,"```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap.umap_ as umap
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.nei...",5,"The generated code addresses some aspects of the task but misses critical components. Key issues include:  
1. **Incomplete Preprocessing**: Missing handling of 'Year_of_Release', improper encoding (LabelEncoder instead of OneHotEncoder), and incomplete feature engineering (e.g., 'Regional_Sales_Distribution' is stored as a list rather than separate features).  
2. **Limited Clustering Analysis**: While KMeans, DBSCAN, Agglomerative, and GMM are implemented, the code lacks detailed optimal cluster selection (e.g., no comprehensive silhouette/elbow analysis for all algorithms) and uses a simplistic consensus clustering approach.  
3. **Missing Advanced Techniques**: No t-SNE/UMAP visualization, no proper gap statistic implementation, and no detailed cluster profiling with statistical tests (ANOVA/chi2).  
4. **Anomaly Detection**: Uses LocalOutlierFactor but lacks the robustness of IsolationForest and no integration with clustering results.  
5. **Association Rules**: Basic implementation without proper transaction encoding or meaningful rule analysis.  
6. **Validation**: Only basic metrics (silhouette, CH, DB) are computed, missing external validation and comprehensive profiling.  
The code is structurally sound but fails to meet the task's depth and completeness requirements.",gpt_4o,LLM_judge_config
H13,hard,Advanced Machine Learning and Ensemble Methods,diabetes.csv,"```python
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")

from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_au...",5,"The generated code addresses some core aspects of the task but falls short in several critical areas. While it includes basic ensemble methods (Voting, Bagging, Stacking, Boosting), Bayesian optimization, and SHAP interpretation, it lacks the comprehensive implementation required. Key omissions include:  
1. **Incomplete Feature Engineering**: Missing advanced techniques like PolynomialFeatures, interaction terms, and proper handling of categorical features (e.g., CatBoost's native support).  
2. **Limited Ensemble Diversity Analysis**: Only pairwise model comparisons instead of a full correlation matrix or diversity metrics.  
3. **Simplified Bayesian Optimization**: Focuses on LGBM with a minimal objective function, whereas the ground truth tunes XGBoost and integrates optimization into the pipeline.  
4. **Insufficient Nested Cross-Validation**: Only applies nested CV to a single model (LGBM) instead of evaluating all models.  
5. **Basic Model Calibration**: Only a calibration curve without Brier scores or reliability analysis.  
6. **Missing Advanced Techniques**: No implementation of custom dynamic weight assignment, calibration with multiple methods (isotonic/sigmoid), or comprehensive SHAP visualization (e.g., dependence plots).  
7. **Code Structure**: Some steps (e.g., preprocessing) are overly simplistic compared to the ground truth's robust pipeline.  

To improve, the code needs deeper integration of all required components, more rigorous feature engineering, and thorough evaluation of all models with nested CV and calibration.",gpt_4o,LLM_judge_config
H14,hard,Advanced Statistical Modeling and Bayesian Analysis,diabetes.csv,"```python
import pandas as pd
import numpy as np
import pymc3 as pm
import arviz as az
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from patsy import dmatrix
from scipy import stats

# 1. Load and preprocess dataset
df = pd.read_csv('diabetes.csv')

# Handle missing values
imputer = SimpleImputer(strategy='mean')
df_imputed = pd.DataFrame(imputer...",5,"The generated code attempts to address the task but has several critical issues. 1) Missing value handling is incomplete (uses mean imputation for all columns instead of targeted zeros and adds a simulated 'region' variable for hierarchical modeling instead of using meaningful grouping like age groups). 2) The PSM implementation incorrectly uses 'Outcome' as the treatment variable, which violates causal inference principles. 3) The GP model uses a binary outcome (Outcome) which is inappropriate for Gaussian Processes (meant for continuous targets). 4) The IV analysis uses frequentist IV2SLS from linearmodels instead of Bayesian methods. 5) The informative priors in logistic regression are generic (mean 0, sigma 1.5) rather than medically informed as in the ground truth. 6) The simulated survival data lacks proper time-to-event logic (uses exponential distribution without meaningful relationships to outcome). 7) Key validation steps (credible intervals, detailed PPC visualization) are present but lack the depth and specificity of the ground truth implementation. The code shows understanding of Bayesian concepts but fails to implement domain-specific knowledge and proper causal modeling techniques.",gpt_4o,LLM_judge_config
H15,hard,Advanced Clustering and Patient Segmentation,diabetes.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans, DBSCAN, SpectralClustering, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, pairwise_distances
from sklearn.neighbors import NearestNeighbors
from sklearn.mode...",6,"The generated code partially addresses the task but misses several key components. 1) **Correctness**: It lacks proper missing data handling (0s in features like Glucose/BloodPressure not replaced with NaN as in ground truth), incomplete statistical tests (no chi2_contingency or Kruskal-Wallis for categorical/continuous features in phenotype analysis), and limited anomaly detection (only IsolationForest instead of DBSCAN, OneClassSVM, and LOF). 2) **Code Quality**: Missing imports for DBSCAN and OPTICS in clustering, redundant code (e.g., unused `train_test_split`), and inefficient consensus clustering implementation (double nested loops for co-occurrence matrix). 3) **Completeness**: Key requirements are missing: - No time-series clustering implementation (only a placeholder) - No clinical risk stratification with detailed phenotype interpretation - No statistical validation of clustering parameters (gap statistic not properly integrated) - Phenotype profiles lack detailed statistical testing and visualization. The code has good structure for some parts but fails to fully implement the advanced analysis steps required in the ground truth.",gpt_4o,LLM_judge_config
H16,hard,Advanced Machine Learning and Ensemble Methods,world-happiness-report-2021.csv,"```python
# Imports
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

from sklearn.ensemble import VotingRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression,...",6,"The generated code addresses several core aspects of the task but falls short in comprehensiveness and depth compared to the ground truth. Key issues include: 1) **Incomplete Ensemble Implementation**: Missing key ensemble methods like CatBoost, complete voting regressor configurations, and detailed boosting implementations. 2) **Limited Hyperparameter Tuning**: Only XGBoost is tuned with Optuna, while other models lack hyperparameter optimization. 3) **Simplified Preprocessing**: Lacks advanced feature engineering (e.g., polynomial features are added but not fully integrated with the pipeline) and proper column dropping. 4) **Insufficient Model Evaluation**: Nested cross-validation is minimal, and advanced metrics like SHAP interaction plots or detailed calibration analysis are missing. 5) **Partial Custom Ensemble**: The dynamic weighting approach is simplistic compared to the ground truth's OOF-based optimization. 6) **Limited Interpretation**: SHAP and LIME usage is basic, without the detailed visualizations and explanations in the ground truth. To improve, the code should integrate all ensemble methods, expand hyperparameter tuning, enhance preprocessing, and include more comprehensive evaluation and interpretation techniques.",gpt_4o,LLM_judge_config
H17,hard,Advanced Statistical Modeling and Causal Inference,world-happiness-report-2021.csv,"```python
# Imports
import pandas as pd
import numpy as np
import pymc3 as pm
import arviz as az
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import KNNImputer
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
from scipy import stats
import semopy
from semopy import Model as SEMModel
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import train_test_split

# 1. Lo...",6,"The generated code addresses several key aspects of the task but falls short in critical areas. **Correctness**: While it implements hierarchical models, SEM, causal inference, and Bayesian regression, it uses `semopy` instead of PyMC3 for SEM, which deviates from the ground truth. The PSM implementation has issues (e.g., incorrect treatment definition, undefined columns like `ladder_score_x`). **Code Quality**: Proper imports and structure are present, but some parts (e.g., variable naming mismatches, incomplete handling of categorical variables) reduce robustness. **Completeness**: It misses detailed preprocessing (e.g., no OneHotEncoding for regions), lacks Gaussian Processes, and simplifies mediation analysis. The hierarchical model is oversimplified compared to the ground truth. **Key Missing Elements**: Comprehensive missing value handling for non-numeric columns, proper SEM implementation with PyMC3, and full Bayesian model validation (e.g., WAIC/LOO-CV plots). To improve, align with PyMC3 for all Bayesian components, enhance preprocessing, and refine causal inference methods.",gpt_4o,LLM_judge_config
H18,hard,Advanced Clustering and Country Segmentation,world-happiness-report-2021.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, pairwise_distan...",5,"The generated code addresses some core aspects of the task but lacks depth and comprehensiveness. While it implements multiple clustering algorithms (KMeans, DBSCAN, etc.) and basic dimensionality reduction (PCA, t-SNE, UMAP), it misses advanced feature engineering, proper optimization of clustering parameters, and detailed statistical analysis. The code uses simplistic approaches for consensus clustering and anomaly detection, and the policy insights are minimal. Key elements like autoencoders, manifold learning, and detailed statistical significance testing (e.g., effect size, stability analysis) are absent. The code structure is functional but lacks modularity (e.g., no class-based organization), and critical steps like geopolitical validation and comprehensive country profiling are underdeveloped. To improve, the code needs to incorporate advanced feature engineering, rigorous parameter optimization, and deeper statistical analysis as outlined in the ground truth solution.",gpt_4o,LLM_judge_config
H19,hard,Time Series Analysis,synthetic_covid19_data.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pmdarima import auto_arima
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_squared_error
from math import sqrt

# 1. Load data
data = pd.read_csv('synthetic_covid19_data.csv', parse_dates=['date'])
data = data[data['location'] == 'Germany']
data.set_index('date', inplace=True)

# 2. Select variables and handle missing values
df = data[['new_cases', 'stringency_index', 'pe...",5,"The generated code addresses most of the task requirements but has critical issues in forecasting implementation. The primary problem is using `results.predict()` instead of `get_forecast()` for out-of-sample predictions, which leads to incorrect forecasts as `predict()` is for in-sample predictions. The code also lacks error handling for insufficient data length (e.g., when the dataset for Germany has fewer than 30 days) and does not explicitly check for remaining NaNs after imputation. While the structure and imports are correct, the forecasting method discrepancy and missing safeguards reduce its reliability and correctness. To improve, replace `predict()` with `get_forecast()` and add checks for data sufficiency.",gpt_4o,LLM_judge_config
H2,hard,Statistical Testing,winequality-red.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import shapiro, normaltest
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import scikit_posthocs as sp

# Load dataset
df = pd.read_csv('winequality-red.csv')

# Define quality categories
def quality_category(score):
    if score <= 4:
        return 'low'
    elif score <= 6:
        return 'medium'
    else:
        return 'high'

df['qualit...",6,"The generated code addresses the core requirements but has critical shortcomings. While it correctly categorizes quality tiers, performs ANOVA/Kruskal-Wallis tests, and creates box plots, it misses key details:  
1. **Missing Normality Checks**: The code samples data for Shapiro-Wilk tests (up to 500 samples), which may not reflect true distributional properties. The ground truth uses full data.  
2. **No Homogeneity of Variance Check**: The generated code skips Levene's test for equal variances, which is required by the task.  
3. **Incomplete Post-hoc Analysis**: The post-hoc results are not fully printed or structured (e.g., `posthoc_dunn` is stored but not explicitly summarized). The ground truth provides detailed post-hoc tables.  
4. **Quality Order in Plots**: The generated code does not set the categorical order for `quality_label`, risking incorrect visualization order.  
5. **Error Handling**: Missing file existence checks, unlike the ground truth.  
6. **Summary Details**: The summary only lists significant features with p-values, not the full test results or post-hoc comparisons.  
Improvements like explicit data sufficiency checks, Levene's test, and structured post-hoc reporting would elevate the code to match the ground truth's rigor.",gpt_4o,LLM_judge_config
H20,hard,Classification,synthetic_covid19_data.csv,"```python
# Imports
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import roc_auc_score, f1_score
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Load data
df = pd.read_csv...",6,"The generated code addresses most requirements but has critical issues in feature engineering and SHAP implementation. 1) **Days since first case**: Uses `cumcount()` instead of actual date differences, which may misrepresent time since first case if dates are not consecutive. 2) **SHAP explanation**: Uses test data (`X_test_scaled`) instead of training data, which is less common for global feature importance. 3) **Missing values**: Fills all with 0, whereas the ground truth uses a more nuanced forward-fill then 0-fill strategy. 4) **Target variable**: Correct logic but could be more robust by explicitly handling NaN thresholds (though the current approach works). The code is well-structured with proper imports and uses `TimeSeriesSplit`, which is appropriate. Improvements in precise date-based feature engineering and SHAP analysis would increase accuracy.",gpt_4o,LLM_judge_config
H21,hard,Statistical Modeling,synthetic_covid19_data.csv,"```python
# Import necessary libraries
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Step 1: Load data and preprocess
# Load the data and parse dates
df = pd.read_csv('synthetic_covid19_data.csv', parse_dates=['date'])

# Calculate vaccination percentage
df['vaccination_percentage'] = df['people_fully_vaccinated'] / df['population'] * 100

# Step 2: Handle missing values
# ...",6,"The generated code addresses many aspects of the task but has several critical issues. 1) **Correctness**: While the model formula is correct (using `stringency_index * vaccination_percentage` for interaction), it uses median imputation instead of the required interpolation or median imputation grouped by location (the ground truth emphasizes time-series alignment). The code also drops rows with remaining missing values, whereas the ground truth fills them with global medians. Additionally, it lacks handling for division by zero in vaccination percentage and doesn't sort the data by `location`/`date` for temporal consistency. 2) **Code Quality**: Missing error handling for file loading (e.g., `FileNotFoundError`), and the `groups` argument in `mixedlm` uses a manually constructed `continent_location` column, which is less robust than the ground truth's explicit nested group ID. 3) **Completeness**: Does not fully implement the ground truth's data preprocessing (e.g., numeric conversion, capping vaccination percentage at 100%) or detailed interpretation of coefficients (e.g., expected direction checks). Model assumptions are mentioned but not elaborated as thoroughly as required. The code could be improved with more explicit data validation and convergence safeguards during model fitting.",gpt_4o,LLM_judge_config
H22,hard,Clustering,clash_royale_cards.csv,"```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# 1. Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# 2. Select features
features = df[['elixirCost', 'Win Rate', 'Usage']]

# 3. Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(features)

# 4. Determine optimal number of clu...",7,"The generated code correctly implements the core steps of the task, including loading the dataset, selecting features, standardizing, determining K using silhouette scores, applying K-Means, performing PCA, and creating a scatter plot. However, it lacks critical robustness features from the ground truth: no error handling for missing files/columns, no checks for feature existence, and no detailed output statements (e.g., dataset shape, feature statistics). While the code is functional, these omissions reduce its reliability and completeness. Improvements would include adding try-except blocks, validating feature presence, and optionally including print statements for user feedback. The choice of silhouette scores is valid, but the ground truth's use of the elbow method is also acceptable. Overall, the code meets the basic requirements but misses key best practices for production-grade code.",gpt_4o,LLM_judge_config
H23,hard,Regression,clash_royale_cards.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import OneHotEncoder

# Load dataset
df = pd.read_csv('clash_royale_cards.csv')

# Select features and target
X = df[['elixirCost', 'Usage', 'rarity']]
y = df['Win Rate']

# One-hot encode 'rarity'
X = pd.get_dummies(X, columns=['rarity'], drop_first=True)

# Split into train and t...",8,"The generated code correctly addresses the core requirements: it loads the dataset, selects the specified features and target, performs one-hot encoding on 'rarity', splits the data, trains a RandomForestRegressor, and evaluates using R2 and MSE. The code is concise, well-structured, and includes necessary imports. However, it lacks error handling for missing files, missing columns, and missing data (e.g., `dropna()`), which are present in the ground truth code. While these omissions might not violate the task's explicit instructions, they reduce robustness. Including checks for column existence and handling missing values would make the code more reliable in real-world scenarios. The code also omits informative print statements about the training process, which, while not critical, are useful for transparency. Overall, the generated code is correct and complete for the task but could benefit from additional safeguards.",gpt_4o,LLM_judge_config
H24,hard,Hypothesis Testing,clash_royale_cards.csv,"```python
import pandas as pd
from scipy import stats

# 1. Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# 2. Identify unique categories in the 'rarity' column
rarity_categories = df['rarity'].unique()
print(""Rarity categories:"", rarity_categories)

# 3. Prepare data for ANOVA
groups = [df[df['rarity'] == rarity]['Win Rate'].dropna() for rarity in rarity_categories]

# 4. State hypotheses
# Null hypothesis H0: All group means (Win Rate) are equal across rarity categories
# Altern...",6,"The generated code partially addresses the task but lacks critical error handling and data validation steps. It does not handle potential file loading errors (e.g., FileNotFoundError) or verify that the 'Win Rate' column is numeric, which could cause runtime failures. The code also fails to check if there are at least two rarity groups or ensure each group has sufficient observations (minimum 2) for ANOVA, risking invalid tests. While hypotheses are correctly stated in comments, they should be printed explicitly as in the ground truth. The p-value interpretation is present but lacks formatted output (e.g., 4 decimal places) and does not explicitly confirm whether the null hypothesis is rejected/fail to reject. The code structure is clean but misses robustness features required for production-grade analysis.",gpt_4o,LLM_judge_config
H25,hard,Classification,iris.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 1) Load the dataset
df = pd.read_csv('iris.csv')

# 2) Define features and target
X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidth...",9,"The generated code correctly addresses all task requirements with minor deviations. It properly loads the dataset, encodes the target variable, splits data with 80/20 split and random_state=42, trains all three required models with correct parameters, and evaluates metrics (accuracy, macro-precision, macro-recall, macro-F1). The code quality is high with proper imports and structure. The only minor issues are: 1) Missing the try-except block for file loading (but the task didn't explicitly require error handling), 2) Not using stratify in train_test_split (though the task didn't specify this requirement). The code is concise, readable, and fully functional for the given task. The only critical difference from the ground truth is the model name labeling (""SVM"" vs ""Support Vector Machine (SVC)"" which doesn't affect functionality).",gpt_4o,LLM_judge_config
H26,hard,Clustering,iris.csv,"```python
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('iris.csv')

# Select the features
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
X = df[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply K-Means clustering
kmeans = KMeans(n_...",7,"The generated code correctly performs K-Means clustering and PCA on the iris dataset with proper imports, structure, and formatting. It addresses all core requirements: loading data, selecting features, standardizing, clustering, PCA, and creating two scatter plots. However, it lacks two key completeness elements from the ground truth: (1) the first plot does not include a colorbar label for cluster assignments (""K-Means Cluster""), and (2) the second plot uses numerical encoded labels without mapping them to actual species names in the colorbar (via `label_encoder.inverse_transform`). While the code works functionally, these omissions reduce clarity for interpretation, which were explicitly included in the ground truth. Improving these details would make the plots more informative and align them closer to the expected output.",gpt_4o,LLM_judge_config
H27,hard,Feature Engineering,iris.csv,"```python
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import GradientBoostingClassifier

# Load dataset
df = pd.read_csv('iris.csv')

# Create new features
df['PetalArea'] = df['PetalLengthCm'] * df['PetalWidthCm']
df['SepalArea'] = df['SepalLengthCm'] * df['SepalWidthCm']

# Define features and target
feature_cols = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'PetalArea', 'Sep...",10,"The generated code correctly implements all required steps with high accuracy. It properly loads the dataset, creates the specified features (PetalArea and SepalArea), includes all six features in X, encodes the target variable with LabelEncoder, initializes the Gradient Boosting Classifier with the correct parameters, performs 5-fold cross-validation, and reports the mean accuracy. The code is clean, well-structured, and includes all necessary imports. The only minor difference from the ground truth is the absence of explicit error handling for file loading, but the task explicitly states to assume the CSV is in the current directory, making this omission acceptable. The solution fully meets all requirements with no critical errors.",gpt_4o,LLM_judge_config
H28,hard,Classification,heart.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# 1. Load the dataset
df = pd.read_csv('heart.csv')

# 2. Define features and target
feature_columns = ['Age', 'Sex',...",8,"The generated code is mostly correct and well-structured, addressing all core requirements. It correctly loads the dataset, defines features/target, preprocesses data with one-hot encoding and scaling, splits the data, trains the model, and evaluates metrics. However, it lacks `stratify=y` in `train_test_split`, which could lead to imbalanced splits and affect evaluation reliability. The `OneHotEncoder` uses `drop='first'` instead of `handle_unknown='ignore'`, which is not critical but differs from the ground truth. These minor deviations reduce the score slightly. The code is clean, properly formatted, and includes all required imports. Adding stratification and aligning encoder parameters would make it fully equivalent to the ground truth.",gpt_4o,LLM_judge_config
H29,hard,Clustering,heart.csv,"```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('heart.csv')

# Select specified numerical features
features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
X = df[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determ...",7,"The generated code correctly implements K-Means clustering and PCA but misses some key elements. It lacks error handling for file loading (no try-except block), omits detailed print statements showing WCSS/silhouette values for each K, and does not explicitly justify the choice of K (hardcoded as 3 without explanation). While the plots are generated, the visualization uses a colorbar instead of a legend for cluster labels, which is less intuitive than the ground truth's approach. The code also doesn't display the explained variance ratio from PCA, which was part of the evaluation criteria. The structure is clean but could benefit from more comments and step-by-step output for clarity.",gpt_4o,LLM_judge_config
H3,hard,Machine Learning,winequality-red.csv,"```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report

# Load dataset
df = pd.read_csv('winequality-red.csv')

# Create binary target variable: 1 if quality >= 7 ('good'), 0 otherwise ('bad')
df['target'] = (df['quality'] >= 7).astype(int)

# Drop original 'quality' column
d...",6,"The generated code addresses most requirements but has critical issues. **Correctness**: The code correctly creates the binary target and trains a logistic regression model, but it scales the entire dataset before splitting, causing data leakage (a major flaw). It also uses `dropna()` instead of handling missing values with imputation, which is less robust. The feature importance uses original feature names instead of scaled ones, leading to misinterpretation. **Code Quality**: Proper imports and structure are present, but it lacks error handling for missing files. **Completeness**: It misses key steps like proper preprocessing (e.g., stratified splits, imputation) and detailed evaluation reporting. To improve, address data leakage by scaling after splitting, handle missing values with imputation, and ensure feature names match scaled data.",gpt_4o,LLM_judge_config
H30,hard,Statistical Modeling,heart.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
import numpy as np

# 1. Load the dataset
df = pd.read_csv('heart.csv')

# 2. Create a box plot showing the distribution of Oldpeak for HeartDisease=0 and 1
sns.boxplot(x='HeartDisease', y='Oldpeak', data=df)
plt.title('Box Plot of Oldpeak by HeartDisease')
plt.xlabel('HeartDisease')
plt.ylabel('Oldpeak')
plt.show()

# 3. Perform a logistic regression with only ...",7,"The generated code correctly loads the dataset, creates a box plot, performs logistic regression, and calculates proportions for discretized `Oldpeak` bins. However, it misses the **interpretation of the logistic regression coefficient** in terms of odds ratios (the ground truth explicitly requires this explanation). Additionally, while it computes proportions, it **does not visualize them** as the ground truth does, which is a completeness gap. Code quality is good with proper imports and structure, but lacks error handling (e.g., for missing values or `pd.qcut` failures). Variable naming for bins uses lowercase (`Oldpeak_bin`), whereas the ground truth uses uppercase (`Oldpeak_Bin`), which is a minor style discrepancy. These omissions reduce the score despite functional correctness.",gpt_4o,LLM_judge_config
H31,hard,Classification,spotify_2023.csv,"```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix

# Step 1: Load data
df = pd.read_csv('spotify_2023.csv')

# Step 2: Convert 'streams' to numeric, coerce errors to NaN, drop NaNs
df['streams'] = pd.to_numeric(df['streams'], errors='coerce')
df = df.dropna(subset=['streams'])
...",9,"The generated code correctly addresses all the requirements and closely follows the task specifications. It properly loads the data, converts `streams` to numeric, creates the `is_popular` target variable using the 75th percentile, selects the required features, performs one-hot encoding on `key` and `mode`, splits the data, trains a Logistic Regression model with `max_iter=1000`, and evaluates the model with F1-score (macro), ROC AUC, and confusion matrix. The code is concise, clean, and uses appropriate imports. The only minor issue is that it does not include error handling for file loading (e.g., `try-except` block), which the ground truth code includes. Additionally, the `OneHotEncoder` is imported but not used, which is a minor redundancy. These issues are not critical, and the code would function correctly as per the task.",gpt_4o,LLM_judge_config
H32,hard,Clustering,spotify_2023.csv,"```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# 1. Load data
df = pd.read_csv('spotify_2023.csv')

# 2. Select relevant audio features and drop rows with NaNs
features = [
    'danceability_%',
    'energy_%',
    'valence_%',
    'acousticness_%',
    'instrumentalness_%',
    'liveness_%',
    'speechiness_%',
    'bpm'
]
df_selected = df[features].dropna()...",10,"The generated code is highly correct, complete, and of excellent quality. It successfully performs all required steps: loading the data, selecting specified features and handling NaNs, standardizing, applying K-Means with the correct parameters, reducing dimensions with PCA, visualizing clusters, and calculating mean feature values per cluster. The code is concise, uses proper imports, and follows best practices like avoiding unnecessary copies (though the ground truth includes more detailed comments). The only minor omission is error handling for missing files, but the task assumes the CSV is present. The code meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
H33,hard,Trend Analysis,spotify_2023.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# 1. Load data
df = pd.read_csv('spotify_2023.csv')

# 2. Convert 'streams' to numeric; coerce errors to NaN
df['streams'] = pd.to_numeric(df['streams'], errors='coerce')

# 3. Filter data
filtered_df = df[
    (df['streams'] > 10_000_000) &
    (df['released_year'] >= 2010) &
    (df['released_year'] <= 2023)
].dropna(subset=['streams'])

# 4. Group by 'released_year'
grouped = filtered_df.groupby('released_year')

# 5. Calculate av...",9,"The generated code correctly addresses all the requirements with proper structure and functionality. It loads the data, converts 'streams' to numeric with error coercion, filters as specified (streams >10M and released_year 2010-2023), drops NaNs, groups by year, calculates the required averages, and creates three line plots with titles/labels. The code is concise, uses appropriate imports, and ensures the plots display properly. The only minor improvement would be adding error handling for missing files (as in the ground truth) to make it more robust, but the task explicitly states to assume the CSV is in the current directory. The code's approach of creating separate figures for each plot is valid, though the ground truth's subplot method is more space-efficient. Overall, the solution is correct and complete.",gpt_4o,LLM_judge_config
H34,hard,Regression,youtube_trendings.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import OneHotEncoder

# Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# Clean 'Likes', 'Dislikes', and 'Video views' columns
for col in ['Likes', 'Dislikes', 'Video views']:
    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce').fillna(...",9,"The generated code correctly addresses all the task requirements with concise and effective implementation. It properly loads the dataset, cleans the numeric columns by removing commas and converting to numeric types with zero-filling, handles the 'published' column by extracting the year as a numeric feature, fills missing values in 'Category' and applies one-hot encoding, defines features and target variables accurately, splits the data with the correct random state, trains a Linear Regression model, and evaluates it with R2 and MAE. The code is well-structured, uses efficient pandas operations, and avoids unnecessary complexity. The only minor omission is not explicitly converting cleaned numeric columns to integers (as in the ground truth), but the problem only required them to be numeric, which the code achieves. The generated code is highly readable and functions as intended.",gpt_4o,LLM_judge_config
H35,hard,Trend Analysis,youtube_trendings.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# Clean 'Video views' column: remove commas, convert to numeric, fill NaNs with 0
df['Video views'] = pd.to_numeric(df['Video views'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)

# Ensure 'published' column is numeric
df['published'] = pd.to_numeric(df['published'], errors='coerce').astype('Int64')

# Drop rows with missing 'published' years
df = df.dropna...",7,"The generated code correctly loads the dataset, cleans the 'Video views' column, and creates the required subplots. However, it assumes the 'published' column is already numeric, whereas the task requires extracting the year from a potential datetime string (as shown in the ground truth). This omission could lead to incorrect grouping if the original 'published' column is a date string. Additionally, the code lacks error handling for file loading and doesn't explicitly filter out invalid years (e.g., 0) like the ground truth. While the structure is clean and meets most requirements, the lack of robustness in handling the 'published' column and missing error handling reduces its completeness. Improving these aspects would elevate the score.",gpt_4o,LLM_judge_config
H36,hard,Text Feature EDA,youtube_trendings.csv,"```python
import pandas as pd
import re
from collections import Counter
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')

# 1) Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# 2) Create 'title_word_count' from 'Video' column
df['title_word_count'] = df['Video'].astype(str).apply(lambda x: len(x.split()))

# 3) Clean 'Video views' column
df['Video views'] = df['Video views'].astype(str).str.replace(',', '', regex=False)
df['Video views'] = pd.to_numeric(df['Vi...",8,"The generated code correctly addresses most requirements, including loading the dataset, creating the title word count, cleaning video views, calculating the correlation, and processing titles for 2023/2024 videos. It includes proper imports and uses efficient methods like `re.findall` for tokenization. However, it lacks error handling for missing files (e.g., `FileNotFoundError`) and does not explicitly handle potential parsing errors in the `published` column (e.g., `errors='coerce'`). The title processing step also omits checking `word.isalpha()` to exclude non-alphabetic tokens, which the ground truth includes. These minor gaps reduce robustness but do not invalidate the core functionality. Strong points include concise code structure and correct use of NLTK for stop words.",gpt_4o,LLM_judge_config
H37,hard,Classification,mobiles_2025.csv,"```python
import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, roc_auc_score

# 1. Load data
df = pd.read_csv('mobiles_2025.csv')

# 2. Clean 'Launched Price (USA)'
df['Launched Price (USA)'] = df['Launched Price (USA)'].astype(str).str.replace('USD ', '', regex=False).str.replace(',', '')
df['Launched Price (USA)'] = pd.to_numeric(df['Launched Price (USA)'],...",7,"The generated code addresses most requirements but has some critical issues. Correctness: It correctly loads data, cleans the target variable, and handles feature cleaning. However, the camera extraction uses a less precise regex (only captures first number vs. MP-specific pattern) and lacks handling for decimal values. The code also doesn't check if categorical columns exist before encoding, which could cause errors. Code quality: Proper structure and imports, but the camera extraction function could be more robust. Completeness: Missing checks for edge cases (e.g., single-class test sets in evaluation) and doesn't handle potential errors during one-hot encoding. The code also directly modifies original columns instead of creating cleaned copies, which could lead to unintended side effects. To improve, add column existence checks, refine regex patterns, and include error handling for evaluation metrics.",gpt_4o,LLM_judge_config
H38,hard,Price Analysis,mobiles_2025.csv,"```python
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv(""mobiles_2025.csv"")

# Function to clean price columns
def clean_price(value):
    if pd.isna(value):
        return np.nan
    try:
        # Remove currency symbols and commas
        for symbol in ['PKR', 'INR', 'CNY', 'USD', 'AED']:
            value = str(value).replace(symbol, '')
        value = value.replace(',', '').strip()
        return pd.to_numeric(value, errors='coerce')
    except:
        return...",10,"The generated code correctly addresses all requirements. It loads the dataset, defines a clean_price function that handles currency symbols, commas, and errors, applies the function to the specified columns, calculates the average global price using mean with skipna=True, and identifies the top 5 models by sorting and selecting the highest values. The code is well-structured, uses appropriate imports, and includes proper handling of missing data. The only minor point is the absence of explicit error handling for file not found, but the task assumes the CSV is present. The code is concise, efficient, and meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
H39,hard,Comparative Analysis,mobiles_2025.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# 1) Load the dataset
df = pd.read_csv('mobiles_2025.csv')

# 2) Clean columns
def clean_numeric_column(series, remove_str):
    return pd.to_numeric(series.str.replace(remove_str, '', regex=False)
                                  .str.replace(',', '', regex=False)
                                  .str.strip(), errors='coerce')

df['RAM_Clean'] = clean_numeric_column(df['RAM'], 'GB')
df['Battery_Capa...",7,"The generated code addresses most requirements but has critical omissions. It correctly loads the dataset, cleans the specified columns, filters for Apple products, and generates box plots. However, it fails to convert the 'Launched Year' column to numeric, which could cause grouping errors if the original data is non-numeric. The code also lacks error handling for missing files, which the ground truth code includes. Additionally, while the generated code uses new columns (e.g., 'RAM_Clean') instead of modifying original columns, this isn't a major issue. To improve, add explicit conversion of 'Launched Year' to numeric and include file existence checks. The box plots are properly structured with titles and labels, showing strong code quality in visualization.",gpt_4o,LLM_judge_config
H4,hard,Advanced Machine Learning,titanic.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score, cross_validate, validation_curve, learning...",6,"The generated code addresses some aspects of the task but lacks depth and completeness in several critical areas. 

**Correctness**:  
- The code performs basic data preprocessing (feature engineering, missing value imputation, encoding), but it misses advanced techniques like custom transformers, interaction terms, and polynomial features within a pipeline.  
- It includes ensemble methods (Voting and Stacking) but lacks detailed hyperparameter tuning for all models (e.g., XGBoost is omitted, and parameter grids are too small).  
- SHAP is used for interpretation, but LIME is missing, and the feature engineering is less sophisticated than the ground truth.  

**Code Quality**:  
- Imports are complete, and the structure is logical, but the code lacks modularity (e.g., no custom transformers or pipelines for preprocessing).  
- The use of `pd.get_dummies` for encoding is basic compared to the ground truth's `ColumnTransformer` and `OneHotEncoder`.  
- Some sections (e.g., SHAP analysis) have incomplete handling of feature names after transformations.  

**Completeness**:  
- **Preprocessing**: Missing advanced feature engineering (e.g., cabin deck extraction, text mining from names), and polynomial features are added post-hoc without integration into a pipeline.  
- **Hyperparameter Tuning**: Uses `GridSearchCV` with limited parameter ranges, while the ground truth uses `RandomizedSearchCV` with more extensive exploration.  
- **Feature Selection**: Only basic techniques (SelectKBest, RFE, mutual info) are implemented, without comparative analysis or integration into pipelines.  
- **Evaluation**: Lacks stratified K-fold cross-validation, learning/validation curves, and detailed statistical tests (e.g., paired t-tests) across all models.  
- **Interpretability**: SHAP is used but not as thoroughly as in the ground truth, and LIME is omitted entirely.  

**Key Missing Elements**:  
- Advanced preprocessing pipelines (e.g., `ColumnTransformer`, `PolynomialFeatures` integrated into pipelines).  
- Comprehensive hyperparameter tuning for all models (e.g., XGBoost, SVM).  
- Full feature selection comparison (e.g., RFE, SelectFromModel).  
- Extensive evaluation metrics and visualization (e.g., confusion matrices, ROC curves).  
- Model interpretability with both SHAP and LIME.  

The code provides a functional baseline but fails to meet the advanced requirements of the task.",gpt_4o,LLM_judge_config
H40,hard,Regression,imdb_top_250.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error

# Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# Define features and target
X = df[['Year', 'Runtime']]
y = df['Rating']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = LinearRegression()
model.fit(X_train, y_tr...",6,"The generated code correctly follows the main steps of loading the dataset, defining features and target, splitting data, training a Linear Regression model, and evaluating with R2 and MAE. However, it lacks critical data preprocessing steps present in the ground truth code. Specifically, it does not clean the 'Runtime' column (which may contain non-numeric values like ""X min""), handle missing values, or validate that required columns exist. This makes the code incomplete and potentially error-prone if the dataset has uncleaned data. Additionally, it lacks error handling for file loading and column validation, which reduces robustness. To improve, include data cleaning steps (e.g., removing "" min"" from Runtime) and add checks for column existence/numeric conversion.",gpt_4o,LLM_judge_config
H41,hard,Clustering,imdb_top_250.csv,"```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# 1. Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# 2. Select the features `Rating` and `Runtime` for clustering
features = df[['Rating', 'Runtime']].copy()

# 3. Standardize these features using StandardScaler
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# 4. Apply K-Means clustering
kmeans = KMeans(n_clusters...",7,"The generated code is mostly correct but misses critical data cleaning steps for the 'Runtime' column, which is likely stored as strings with ' min' (e.g., '142 min'). This would cause errors during scaling and plotting, as the code assumes numeric values. Additionally, it does not handle missing values in 'Rating' or 'Runtime' after conversion, which could lead to failed K-Means clustering. The code quality is strong with proper imports and structure, and it addresses all other requirements (scaling, clustering, visualization, and mean calculation). However, the absence of data preprocessing for 'Runtime' and missing value handling reduces correctness and completeness. To improve, add code to convert 'Runtime' to numeric by removing ' min' and drop NaN rows as in the ground truth.",gpt_4o,LLM_judge_config
H42,hard,Text Analysis,imdb_top_250.csv,"```python
import pandas as pd
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from collections import Counter

# Ensure nltk resources are downloaded
nltk.download('punkt')
nltk.download('stopwords')

# Load dataset
df = pd.read_csv('imdb_top_250.csv')

# Create title_length feature
df['title_length'] = df['Title'].astype(str).str.len()

# Calculate and print Pearson correlation
correlation = df['title_length'].corr(df['Rating'], method='pearso...",7,"The generated code addresses most requirements but has critical issues. It correctly loads data, creates title_length, calculates Pearson correlation (though without handling non-numeric/Rating NaNs), preprocesses titles (lowercase, removes punctuation with str.translate, tokenizes, and removes stopwords). However, it lacks proper handling of non-numeric 'Rating' values (which could cause correlation errors) and uses a less robust punctuation removal method (string.punctuation vs regex). The preprocessing step also uses word.isalnum() which may retain some non-alphanumeric characters, whereas the ground truth uses regex for stricter cleanup. The code quality is good but could improve with error handling and more precise text processing.",gpt_4o,LLM_judge_config
H43,hard,Classification,penguins.csv,"```python
import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestClassifier

# 1. Load the dataset
df = pd.read_csv('penguins.csv')

# 2. Define features and target
features = ['culmen_length_mm', 'culmen_depth_mm', 'fli...",6,"The generated code addresses most requirements but has critical omissions. 1) It fails to handle missing values in the target variable `species` (ground truth explicitly drops these rows, but the generated code does not). 2) It does not properly handle the edge case where `island` is entirely NA (SimpleImputer would crash, but the ground truth code has explicit logic to drop such rows). 3) The code splits numerical and categorical processing separately but lacks a unified pipeline, leading to potential misalignment between features and labels after row drops. While the structure is clean and uses scikit-learn pipelines effectively, these missing safeguards for edge cases reduce correctness. Code quality is good, but completeness is compromised.",gpt_4o,LLM_judge_config
H44,hard,Clustering,penguins.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# 1. Load the dataset
df = pd.read_csv('penguins.csv')

# 2. Select the features
features = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
data = df[features + ['species']]

# 3. Drop rows with missing values in selected features
data = data.dropna(subset=features)

...",7,"The generated code correctly performs K-Means clustering and PCA on the penguins dataset, addressing all core requirements. However, it lacks proper imports (e.g., missing `seaborn` for enhanced plots) and uses a manual species-to-color mapping that could be simplified with `hue` in `sns.scatterplot` as in the ground truth. While the plots are functional, they miss seaborn's aesthetic defaults and legend formatting. The code also omits error handling for missing files, which the ground truth includes. Improvements in code structure (e.g., using DataFrames for PCA results) and plot styling would elevate quality.",gpt_4o,LLM_judge_config
H45,hard,Feature Engineering,penguins.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder

# 1. Load dataset
df = pd.read_csv('penguins.csv')

# 2. Impute missing values
# Numeric columns
num_cols = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
for col in num_cols:
    df[col].fillna(df[col].mean(), inplace=True)

# 'sex' column - impute with mode
df['...",5,"The generated code has several critical issues that prevent it from fully solving the task. First, it incorrectly imputes numerical values **before** dropping rows with missing `island` values, which violates the task's requirement to **drop `island` NAs first**. This order of operations leads to inconsistent data processing. Second, the code does not explicitly handle the `island` column during imputation, as the task requires dropping `island` rows prior to imputation. While the rest of the code addresses feature encoding, model training, and visualization, these errors compromise correctness. Additionally, the code lacks a `try-except` block for file loading, though the task assumes the file is present. Code quality is good in terms of structure and imports, but the critical logic flaw in data processing significantly reduces its effectiveness. To improve, the code must strictly follow the required step order and ensure `island` NAs are dropped before imputation.",gpt_4o,LLM_judge_config
H46,hard,Data Cleaning,penguins.csv,"```python
import pandas as pd
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder

# Step 1: Load the dataset
df = pd.read_csv(""penguins.csv"")

# Step 2: KNN Imputation for numerical columns
numerical_cols = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
imputer = KNNImputer(n_neighbors=3)

# Preserve other columns
numerical_data = df[numerical_cols]
imputed_numerical_data = imputer.fit_transform(numerical_data)
df[numerical_cols] = p...",7,"The generated code correctly addresses the core requirements: loading the dataset, applying KNN imputation to the specified numerical columns, and imputing 'sex' with the mode. However, it lacks error handling for missing files (e.g., FileNotFoundError), which the ground truth includes. Additionally, the code assumes the 'sex' column is not entirely null, which could cause a crash if `df['sex'].mode()` returns an empty Series (e.g., if all values are NaN). The generated code also omits the initial print of NA counts before imputation, though the task only explicitly requires post-imputation verification. Code quality is good, but adding safeguards for edge cases (e.g., checking if the mode exists) and including error handling would improve robustness. The structure is clear and concise, meeting the task's main objectives.",gpt_4o,LLM_judge_config
H47,hard,Hypothesis Testing,penguins.csv,"```python
import pandas as pd
from scipy.stats import ttest_ind

# Step 1: Load the dataset
df = pd.read_csv('penguins.csv')

# Step 2: Filter the dataset to include only 'Adelie' and 'Gentoo' species
filtered_df = df[df['species'].isin(['Adelie', 'Gentoo'])]

# Step 3: Drop rows with NA values in the 'culmen_length_mm' column
filtered_df = filtered_df.dropna(subset=['culmen_length_mm'])

# Step 4: Separate the culmen_length_mm values for both species
adelie_culmen = filtered_df[filtered_df['spe...",8,"The generated code correctly implements all the core requirements: loading the dataset, filtering for 'Adelie' and 'Gentoo' species, handling NA values in `culmen_length_mm`, performing the t-test, and interpreting the result. It is concise and avoids unnecessary complexity. However, it lacks error handling for file operations (e.g., `FileNotFoundError`), which the ground truth code includes. It also omits detailed intermediate outputs (e.g., sample counts, means) that provide context for the analysis. Additionally, while the t-test parameters are valid (using `equal_var=False` is acceptable for Welch's t-test), the ground truth explicitly assumes equal variances (`equal_var=True`) as part of its documentation. These omissions slightly reduce completeness and code robustness but do not affect correctness for the given task. For a higher score, adding error handling and intermediate print statements would align it more closely with the ground truth's thoroughness.",gpt_4o,LLM_judge_config
H48,hard,Classification,penguins.csv,"```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1. Load the dataset
df = pd.read_csv(""penguins.csv"")

# 2. Define features and target
feat...",10,"The generated code correctly solves the task with all required steps implemented. It loads the dataset, defines features/target, performs median imputation for numerical features, mode imputation for 'sex', one-hot encoding for 'island' and 'sex', label encoding for 'species', stratified split with random_state=42, trains a RandomForestClassifier with n_estimators=100, and evaluates with accuracy and classification report. The code structure is clean, uses appropriate pipelines and ColumnTransformer, and includes the necessary imports. The only minor difference from the ground truth is the absence of print statements for dataset inspection (which the task didn't explicitly require) and not using .copy() when creating X/y, but these do not affect correctness. The solution is complete, efficient, and follows best practices for preprocessing and modeling.",gpt_4o,LLM_judge_config
H49,hard,Statistical Analysis,,"```python
import pandas as pd

# Create DataFrame
data = {
    ""EmployeeID"": [""E001"", ""E002"", ""E003"", ""E004"", ""E005"", ""E006"", ""E007"", ""E008""],
    ""Department"": [""Sales"", ""HR"", ""Tech"", ""Sales"", ""Tech"", ""HR"", ""Tech"", ""Sales""],
    ""PerformanceScore"": [4, 3, 5, 2, 4, 3, 5, 4],
    ""YearsExperience"": [5, 2, 8, 3, 6, 2, 10, 4],
    ""ProjectsCompleted"": [10, 5, 15, 4, 12, 6, 20, 8],
    ""TrainingHours"": [20, 40, 10, 50, 20, 30, 15, 25]
}
df = pd.DataFrame(data)

# Calculate Pearson correlation coeffi...",10,"The generated code fully satisfies all the requirements of the task. It correctly defines the DataFrame with the specified data, calculates Pearson correlation coefficients between ""PerformanceScore"" and both ""YearsExperience"" and ""TrainingHours"" (note: the `method='pearson'` parameter is redundant here since Pearson is the default in pandas, but the code is still valid), prints both coefficients, and accurately determines which feature has the stronger absolute correlation. The code is well-structured, concise, and avoids unnecessary elements (e.g., no unused imports or redundant print statements). It handles edge cases (equal absolute correlations) and uses clear variable names and logical flow. All aspects of the task are addressed correctly, making this a high-quality solution.",gpt_4o,LLM_judge_config
H5,hard,Advanced Statistical Modeling,titanic.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lifelines import KaplanMeierFitter, CoxPHFitter
from lifelines.statistics import proportional_hazard_test
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import train_test_split
from scipy import stats
import statsmodels.api as sm
import pymc3 as pm
import arviz as az
import seaborn as sns
import warnings

warnings.filterwarnings('i...",6,"The generated code addresses several core components of the task but falls short in several key areas.  

**Correctness:**  
- **Kaplan-Meier Analysis:** The code correctly implements a basic Kaplan-Meier curve by Pclass but misses more detailed stratifications (e.g., by Sex) and fails to handle time-to-event data properly (e.g., using a fixed ""duration"" of 1 for all observations, which is not ideal for survival analysis).  
- **Cox Regression:** The code includes a Cox model and interaction effects, but lacks comprehensive diagnostics (e.g., proportional hazards tests, model validation). The ground truth code uses `proportional_hazards_test` and detailed checks, which are absent here.  
- **Multivariate Analysis:** The code includes a logistic regression for odds ratios, but the ground truth uses advanced techniques (e.g., interaction testing, multivariate analysis).  
- **Propensity Score Matching (PSM):** The PSM implementation is basic, lacking detailed covariate balance checks (e.g., standardized mean differences) and proper handling of treatment vs. control groups.  
- **Bootstrap:** The bootstrap resampling is simplistic (only survival probability, not coefficients or C-index) and lacks the robustness of the ground truth's 500+ iterations with coefficient tracking.  
- **Bayesian Analysis:** The PyMC3 model is rudimentary (only a logistic regression with limited features) compared to the ground truth's comprehensive Bayesian survival model with detailed diagnostics.  

**Code Quality:**  
- Missing critical libraries (e.g., `scikit-learn` utilities for preprocessing, `seaborn` for plots, `statsmodels` for advanced tests).  
- Inconsistent preprocessing (e.g., `dropna()` vs. imputation, lack of feature engineering like `FamilySize`).  
- Poor error handling (e.g., no safeguards for missing data, no checks for model convergence).  

**Completeness:**  
- Missing advanced requirements:  
  - **Model Validation:** No sensitivity analysis, assumption checks, or detailed diagnostics (e.g., AIC/BIC, cross-validation).  
  - **Interaction Effects:** Limited to one interaction term (Age*Fare) instead of comprehensive testing.  
  - **Bayesian Modeling:** Simplified model without full probabilistic inference or prior sensitivity analysis.  
  - **Statistical Rigor:** No multivariate analysis, advanced tests (e.g., chi-square, t-tests), or thorough model comparison.  

**Areas for Improvement:**  
1. Implement proper time-to-event modeling (e.g., using actual time data if available).  
2. Add advanced diagnostics (e.g., proportional hazards tests, model checks, AIC/BIC).  
3. Enhance PSM with covariate balance metrics (e.g., SMD).  
4. Use imputation instead of `dropna()` for missing data.  
5. Expand Bayesian analysis to include more features and prior sensitivity checks.  
6. Include comprehensive model validation (e.g., cross-validation, sensitivity analysis).",gpt_4o,LLM_judge_config
H50,hard,Statistical Modeling & Visualization,,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr

# Create the DataFrame
data = {
    'StudentID': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008', 'S009', 'S010', 'S011', 'S012'],
    'Subject': ['Math', 'Science', 'Math', 'English', 'Science', 'Math', 'English', 'Science', 'Math', 'English', 'Math', 'Science'],
    'Midterm_Score': [85, 92, 78, 88, 76, 95, 82, 89, 70, 91, 65, 77],
    'Final_Score': [90, 88, 82...",9,"The generated code correctly creates the DataFrame, calculates the Pearson correlation coefficient, and generates a scatter plot colored by 'Subject' with appropriate labels, title, and legend. It also adds the 'Overall_Grade' column using a function and prints the grade distribution. The code is well-structured with necessary imports and addresses all requirements. The only minor issues are the absence of `plt.tight_layout()` and slightly different formatting (e.g., two decimal places for the correlation instead of four). These are negligible for functionality, and the plot is still generated as required. The approach using `apply()` for grading is valid, though the ground truth used `np.select`. Overall, the code is correct, complete, and of high quality.",gpt_4o,LLM_judge_config
H51,hard,Data Visualization & Time Series Analysis,,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Create the DataFrame
data = {
    'Date': pd.to_datetime([
        '2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05',
        '2024-01-08', '2024-01-09', '2024-01-10', '2024-01-11', '2024-01-12'
    ]),
    'Ticker': ['TECHCO'] * 10,
    'Open': [150.0, 152.5, 151.0, 153.0, 155.5, 154.0, 156.0, 155.0, 153.0, 150.0],
    'High': [153.0, 153.5, 154.0, 156.0, 157.0, 156.5, 157.5, 156.5, 155.0, 152.0],
    'Low': [14...",9,"The generated code correctly creates the DataFrame with 'Date' as the index, calculates daily returns using `pct_change()`, computes the 3-day and 5-day SMAs with `rolling()`, and generates a properly labeled line plot with all required elements. The code is well-structured, concise, and includes necessary imports. However, it lacks a specific check for cases where no bullish crossovers are found, which would result in printing the header without any dates. This minor oversight in handling edge cases reduces completeness slightly. The crossover logic itself is accurate, and the plot meets all visual requirements. Strong points include correct SMA calculations, proper use of pandas and matplotlib, and clear code organization.",gpt_4o,LLM_judge_config
H52,hard,Data Visualization & Analysis,,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Step 1: Create the DataFrame
data = {
    'OrderID': [101, 102, 103, 104, 105, 106, 107],
    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam', 'Mouse', 'Laptop'],
    'Category': ['Electronics'] * 7,
    'Quantity': [1, 2, 1, 1, 3, 1, 1],
    'Price_USD': [1200, 25, 75, 300, 50, 25, 1150],
    'CustomerID': ['CUST001', 'CUST002', 'CUST001', 'CUST003', 'CUST002', 'CUST004', 'CUST001']
}

df = pd.DataFrame(data)

# Ste...",9,"The generated code correctly creates the DataFrame, calculates product revenue, generates a horizontal bar chart, computes the average order value, and identifies repeat customers. It addresses all requirements with proper imports and structure. The primary improvements needed are: 1) Sorting product revenue in descending order (as shown in the ground truth) would better highlight top-selling products, and 2) Formatting the repeat customer output with clear headers and alignment (like the ground truth's loop-based display) enhances readability. The average order value calculation is correct but lacks contextual print statements (e.g., total revenue and unique order count) present in the ground truth, though these are not strictly required by the task. The plot is generated as specified, so it meets the criteria. The code is clean and functional but could match the ground truth's detailed output formatting for completeness.",gpt_4o,LLM_judge_config
H53,hard,Feature Engineering,,"```python
import pandas as pd
import numpy as np

# Create the DataFrame
data = {
    ""UserID"": [""User1"", ""User2"", ""User3"", ""User4"", ""User5"", ""User6""],
    ""SessionDurationMinutes"": [15, 25, 10, 30, 22, 18],
    ""PagesViewed"": [5, 8, 3, 10, 7, 6],
    ""DeviceType"": [""Desktop"", ""Mobile"", ""Desktop"", ""Mobile"", ""Desktop"", ""Mobile""],
    ""Converted"": [True, False, False, True, True, False]
}
df = pd.DataFrame(data)

# Step 1: Map DeviceType to numeric
df[""DeviceType_Numeric""] = df[""DeviceType""].map({...",10,"The generated code is fully correct, high-quality, and complete. It correctly defines the DataFrame, creates the ""DeviceType_Numeric"" feature with the specified mapping, computes ""PagesPerMinute"" while handling division by zero (via replacing infinities and NaNs with 0), selects the required features, and prints the head of the resulting DataFrame. The code is concise, uses proper imports, and follows a clear structure. The only minor difference from the ground truth is the approach to filling NaNs (reassigning the Series vs. using `inplace=True`), but both methods are valid and achieve the same result. The code meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
H54,hard,Anomaly Detection,,"```python
import pandas as pd

# Define the data
data = {
    ""Timestamp"": [""2025-05-24 10:00"", ""2025-05-24 10:05"", ""2025-05-24 10:10"", ""2025-05-24 10:15"",
                  ""2025-05-24 10:00"", ""2025-05-24 10:05"", ""2025-05-24 10:20"", ""2025-05-24 10:25""],
    ""SensorID"": [""S1"", ""S1"", ""S1"", ""S1"", ""S2"", ""S2"", ""S1"", ""S2""],
    ""TemperatureCelsius"": [22.5, 22.7, 22.6, 28.0, 21.9, 22.0, 15.0, 22.1],
    ""HumidityPercent"": [55, 56, 55, 57, 60, 59, 70, 58],
    ""AirQualityIndex"": [30, 32, 31, 33, 25, 26...",9,"The generated code correctly defines the DataFrame with all required columns and data, calculates the mean and standard deviation of ""TemperatureCelsius"", identifies outliers using the 1.5 standard deviation threshold, and prints the specified details (SensorID, Timestamp, TemperatureCelsius). It adheres to the task requirements and maintains good code quality with proper imports and structure. However, it lacks the optional but recommended datetime conversion for the ""Timestamp"" column, which the ground truth code includes as best practice. Additionally, the generated code does not handle the case where no outliers are found (no `if not outliers_df.empty` check), but this is not explicitly required by the evaluation criteria. The code is concise and effective, with minor improvements possible for completeness and robustness.",gpt_4o,LLM_judge_config
H55,hard,Advanced Aggregation & Analysis,,"```python
import pandas as pd

# Create the DataFrame
data = {
    ""PostID"": [""SM01"", ""SM02"", ""SM03"", ""SM04"", ""SM05"", ""SM06"", ""SM07"", ""SM08"", ""SM09""],
    ""Platform"": [""Instagram"", ""Twitter"", ""Facebook"", ""Instagram"", ""Twitter"", ""Instagram"", ""Facebook"", ""Twitter"", ""Facebook""],
    ""PostType"": [""Image"", ""Text"", ""Video"", ""Image"", ""Text"", ""Video"", ""Image"", ""Video"", ""Text""],
    ""Likes"": [150, 80, 300, 200, 90, 450, 120, 250, 70],
    ""Shares"": [20, 15, 50, 30, 10, 60, 18, 40, 12],
    ""Comments"": [1...",10,"The generated code correctly defines the DataFrame, calculates the EngagementScore using the specified formula, and accurately identifies the PostType with the highest average EngagementScore for each platform. It uses an efficient method with `groupby` and `idxmax` to achieve the second task, which is valid and concise. The code structure is clean, with clear variable names and proper imports, matching the ground truth's quality. It addresses all requirements as specified. The only minor difference is the absence of a header message in the print statement, but the task only requires printing the platform details, not the exact header. The output formatting (e.g., decimal places) is also acceptable as the problem didn't explicitly mandate it. Overall, the code is correct, well-written, and complete.",gpt_4o,LLM_judge_config
H56,hard,Data Aggregation & Analysis,,"```python
import pandas as pd

# Create the DataFrame
data = {
    ""PatientID"": [""P001"", ""P002"", ""P003"", ""P004"", ""P005"", ""P006"", ""P007"", ""P008""],
    ""AdmissionDate"": pd.to_datetime([""2025-01-10"", ""2025-01-12"", ""2025-01-15"", ""2025-01-18"", ""2025-01-20"", ""2025-01-22"", ""2025-01-23"", ""2025-01-25""]),
    ""DischargeDate"": pd.to_datetime([""2025-01-15"", ""2025-01-16"", ""2025-01-22"", ""2025-01-25"", ""2025-01-24"", ""2025-01-28"", ""2025-01-30"", ""2025-02-02""]),
    ""Diagnosis"": [""Flu"", ""Cold"", ""Flu"", ""Injury"", ""C...",10,"The generated code correctly defines the DataFrame, calculates the ""LengthOfStay"" column using timedeltas, computes the required aggregations (average stay and patient count) per diagnosis, and identifies the diagnosis with the longest average stay. All steps are implemented accurately with proper pandas syntax and logic. The code is concise, clean, and meets the task's requirements without unnecessary complexity. While it lacks the step-by-step print messages present in the ground truth, the evaluation criteria only demanded the final outputs, which are fulfilled. The code is functionally complete and well-structured.",gpt_4o,LLM_judge_config
H57,hard,Feature Engineering & Ranking,,"```python
import pandas as pd

# Define the data
data = {
    ""MovieID"": [""M01"", ""M02"", ""M03"", ""M04"", ""M05"", ""M06"", ""M07"", ""M08""],
    ""Title"": [""Inception"", ""The Dark Knight"", ""Pulp Fiction"", ""Forrest Gump"", ""The Matrix"", ""Interstellar"", ""The Lion King"", ""Fight Club""],
    ""Genre"": [""Sci-Fi"", ""Action"", ""Crime"", ""Drama"", ""Sci-Fi"", ""Sci-Fi"", ""Animation"", ""Drama""],
    ""Year"": [2010, 2008, 1994, 1994, 1999, 2014, 1994, 1999],
    ""Rating"": [8.8, 9.0, 8.9, 8.8, 8.7, 8.6, 8.5, 8.8],
    ""Votes"": [22...",10,"The generated code perfectly solves the task. It correctly defines the DataFrame with all specified columns, calculates the ""WeightedRating"" using the formula (Rating * Votes) / sum(Votes) without any errors, adds the new column as required, and identifies the movie with the highest ""WeightedRating"" using `idxmax()`. The code is concise, clean, and follows proper Python and pandas conventions. It addresses all requirements explicitly stated in the task, including the calculation and output. The only minor difference from the ground truth is the absence of explicit comments, but the task did not mandate them, and the code is self-explanatory. No critical issues or missing functionality were found.",gpt_4o,LLM_judge_config
H58,hard,Data Aggregation,,"```python
import pandas as pd

# Define the DataFrame
data = {
    ""CarID"": [""C001"", ""C002"", ""C003"", ""C004"", ""C005"", ""C006"", ""C007"", ""C008""],
    ""Brand"": [""Toyota"", ""Honda"", ""Ford"", ""Toyota"", ""BMW"", ""Honda"", ""Ford"", ""BMW""],
    ""Model"": [""Camry"", ""Civic"", ""Focus"", ""Rav4"", ""X5"", ""Accord"", ""Mustang"", ""X3""],
    ""Year"": [2020, 2021, 2019, 2022, 2023, 2020, 2021, 2022],
    ""PriceUSD"": [25000, 22000, 18000, 30000, 60000, 24000, 45000, 55000],
    ""Mileage"": [30000, 20000, 45000, 15000, 5000, 35000,...",10,"The generated code correctly defines the DataFrame, calculates the average PriceUSD and Mileage per brand using groupby and mean, creates a new grouped DataFrame with ""Brand"" as a regular column (via reset_index), and prints it. It is concise, follows proper Python syntax, and meets all task requirements. The lack of comments is minor, but the code is clear and functional. The approach using .groupby().mean() is valid and achieves the same result as the ground truth's .agg() method. The output structure (Brand as a column) is acceptable and aligns with the task's ""grouped by Brand"" instruction. No critical errors or omissions detected.",gpt_4o,LLM_judge_config
H59,hard,Feature Engineering & Aggregation,,"```python
import pandas as pd

# Define the data
data = {
    ""PokemonID"": [1, 2, 3, 4, 5, 6, 7, 8, 9],
    ""Name"": [""Bulbasaur"", ""Ivysaur"", ""Venusaur"", ""Charmander"", ""Charmeleon"", ""Charizard"", ""Squirtle"", ""Wartortle"", ""Blastoise""],
    ""Type1"": [""Grass"", ""Grass"", ""Grass"", ""Fire"", ""Fire"", ""Fire"", ""Water"", ""Water"", ""Water""],
    ""Type2"": [""Poison"", ""Poison"", ""Poison"", None, None, ""Flying"", None, None, None],
    ""HP"": [45, 60, 80, 39, 58, 78, 44, 59, 79],
    ""Attack"": [49, 62, 82, 52, 64, 84, 48...",10,"The generated code perfectly addresses all requirements. It correctly defines the DataFrame with the specified data, creates the ""TotalStats"" column using sum(axis=1) which is a concise and efficient approach, accurately identifies the Pokemon with the highest total stats (even handles ties by selecting the first occurrence via .values[0]), and calculates average speed per Type1 using groupby and mean. The code is clean, uses proper pandas syntax, and avoids unnecessary complexity. All three tasks are completed without errors, and the structure aligns with best practices. The only minor difference from the ground truth is the absence of intermediate DataFrame print statements, but the problem explicitly requested ""only Python code"" without requiring visualization, so this is acceptable. The code is fully correct, well-organized, and complete.",gpt_4o,LLM_judge_config
H6,hard,Customer Segmentation,titanic.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap

from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.mixture import GaussianMixture

from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sklearn.metrics import adjusted_rand_score, normal...",6,"The generated code addresses most of the task requirements but has several critical shortcomings. It uses LabelEncoder instead of OneHotEncoder for categorical features, which is inappropriate for clustering as it introduces ordinal relationships where none exist. The code lacks proper social network analysis (e.g., no family group analysis with ticket sharing) and socioeconomic indicators (no advanced title grouping or proper fare calculations). Feature engineering is incomplete, missing text-based features like NameLength and proper ticket prefix categorization. The cluster validation section only uses silhouette score for optimal k selection instead of the comprehensive metrics (elbow, gap statistic, calinski-harabasz) required. Dimensionality reduction visualizations are limited to KMeans clusters rather than showing all algorithms. The code doesn't handle DBSCAN noise points in analysis or implement consensus clustering as specified. While it includes multiple clustering algorithms and some visualizations, the overall approach lacks the systematic preprocessing pipeline and detailed cluster profiling present in the ground truth. The external validation section is also less comprehensive, using only normalized mutual information instead of the full survival pattern analysis.",gpt_4o,LLM_judge_config
H60,hard,Advanced Aggregation & Analysis,,"```python
import pandas as pd

# Define the book inventory data
data = {
    ""BookID"": [""B001"", ""B002"", ""B003"", ""B004"", ""B005"", ""B006"", ""B007""],
    ""Title"": [""The Great Gatsby"", ""To Kill a Mockingbird"", ""1984"", ""Pride and Prejudice"", ""The Hobbit"", ""Animal Farm"", ""Brave New World""],
    ""Author"": [""F. Scott Fitzgerald"", ""Harper Lee"", ""George Orwell"", ""Jane Austen"", ""J.R.R. Tolkien"", ""George Orwell"", ""Aldous Huxley""],
    ""Genre"": [""Classic"", ""Classic"", ""Dystopian"", ""Romance"", ""Fantasy"", ""Dystopi...",9,"The generated code correctly defines the DataFrame, calculates book counts and average prices per author, and identifies the author with the most stock. It uses efficient pandas operations like `groupby` and `agg`, and the logic is sound. The code is concise and well-structured with proper imports. The only minor issue is the output format: it prints the DataFrame directly (which is valid) instead of formatting each row with custom alignment and labels as in the ground truth. While this doesn't affect correctness, adhering to the exact print format specified in the task would make it fully aligned with the ground truth. Overall, the code is correct, complete, and high-quality.",gpt_4o,LLM_judge_config
H7,hard,Advanced Machine Learning,water_potability.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import KNNImputer, SimpleImputer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.model_selection...",5,"The generated code addresses some aspects of the task but misses critical components and has significant shortcomings. Key issues include: 1) Preprocessing lacks advanced strategies (e.g., multiple imputation methods, proper polynomial features with interaction_only=False), uses basic IQR outlier treatment instead of winsorization, and doesn't preserve feature names during transformations. 2) Blending is implemented as a simple averaging function rather than using a proper meta-learner. 3) Evaluation metrics are incomplete (missing precision, recall, F1, and Brier score) and learning/validation curves are limited to one model only. 4) Bootstrap confidence intervals are calculated on training data rather than test data and lack proper implementation. 5) SHAP analysis is rudimentary (beeswarm plot only) and uses only XGBoost. 6) Paired t-tests are applied to cross-validation scores instead of per-fold scores as required. 7) The model comparison dashboard is minimal with only accuracy and AUC, no feature importance or confidence intervals. 8) Calibration only shows one model without comparison to uncalibrated versions. The code structure is messy with inconsistent variable naming and lacks proper error handling.",gpt_4o,LLM_judge_config
H8,hard,Advanced Statistical Modeling,water_potability.csv,"```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.impute import KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from fancyimpute import IterativeImputer as MICE
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.metrics import classification_report, roc_auc_scor...",5,"The generated code addresses some aspects of the task but has significant gaps. It includes basic implementations of imputation (MICE, KNN, IterativeImputer), logistic regression, GAM, Bayesian modeling, anomaly detection, PCA, and some hypothesis tests. However, it lacks comprehensive comparisons of imputation effectiveness, detailed model diagnostics (e.g., no residual analysis, influence measures, or goodness-of-fit tests), and advanced visualizations like Q-Q plots or leverage plots. The Bayesian model is minimal, and the GAM implementation is overly simplistic. The code also contains errors (e.g., incorrect variable names in MANOVA, missing essential libraries like `pygam` in some contexts). It partially meets the requirements but misses critical elements like robust statistical methods, multivariate ANOVA with proper variable handling, and thorough model evaluation. The code quality is acceptable but lacks the depth and completeness of the ground truth.",gpt_4o,LLM_judge_config
H9,hard,Customer Segmentation,water_potability.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA, FactorAnalysis
from sklearn.manifold import TSNE
import umap.umap_ as umap
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_...",5,"The generated code partially addresses the task but misses critical components. It lacks proper advanced feature engineering (simpler ratios vs. domain-specific indices in ground truth), hardcodes the optimal cluster number (k_opt=4) without validation, and omits the elbow method, gap statistic implementation for K selection, and consensus clustering. Cluster stability analysis is minimal, using bootstrap without proper evaluation metrics. Anomaly detection uses LOF instead of cluster-based methods as requested. While it includes some clustering algorithms and visualizations, the dashboard is less comprehensive (e.g., no 3D visualizations for all DR methods, no interactive elements beyond basic scatter plots). Domain knowledge validation is absent, and the code structure is less organized. Key missing elements include: detailed water quality indices, complete cluster validation techniques, robust stability analysis, and cluster-specific anomaly detection aligned with the task requirements.",gpt_4o,LLM_judge_config
M1,medium,Statistical Analysis,winequality-red.csv,"```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import numpy as np

# Load dataset
df = pd.read_csv('winequality-red.csv')

# Compute correlations with 'quality'
correlation_matrix = df.corr()
quality_corr = correlation_matrix['quality'].drop('quality')

# Top 3 positively correlated features with 'quality'
top_pos = quality_corr.sort_values(ascending=False).head(3)

# Top 3 negatively correlated features with ...",8,"The generated code correctly calculates correlations, identifies top features, creates a heatmap, and generates scatter plots with regression lines. It uses sklearn's LinearRegression instead of scipy's linregress, which is acceptable but differs from the ground truth. The code lacks explicit R² values in the scatter plot labels, which the ground truth includes, but this may not be strictly required. The heatmap and scatter plots are properly formatted, and the code is concise with good structure. Minor improvements could include matching the figure sizes and adding R² annotations for consistency, but the core requirements are fully addressed.",gpt_4o,LLM_judge_config
M10,medium,Hypothesis Testing and Statistical Analysis,video_games_sales.csv,"```python
import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import chi2_contingency, mannwhitneyu
import warnings
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv('video_games_sales.csv')

# Clean data: drop rows with missing values in relevant columns
df_clean = df.dropna(subset=['Publisher', 'Genre', 'Platform', 'Global_Sales', 'Year_of_Release'])

# Convert 'Year_of_Release' to numeric (if not already)
df_clean['Year_of_Release'] = pd.to_num...",6,"The generated code performs the required statistical tests (t-test, chi-square, Mann-Whitney U) and addresses most task requirements. However, it lacks critical elements: 1) **Data cleaning** is minimal (drops missing values in specific columns without handling edge cases like 'User_Score' or ensuring 'Year_of_Release' is numeric as in the ground truth). 2) **Test validation** is missing (no checks for group size adequacy, contingency table validity, or handling of empty datasets). 3) **Interpretation** is overly simplistic (only p-value comparisons without hypothesis statements, test statistics, or detailed explanations). 4) **Error handling** is absent (no file existence checks or contingency table validity checks). While the code is functionally correct for basic execution, it lacks robustness and completeness required for a comprehensive analysis.",gpt_4o,LLM_judge_config
M11,medium,Classification and Machine Learning,video_games_sales.csv,"```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load the dataset
df = pd.read_csv('video_games_sales.csv')

# 2. Handle missing values
df.dropna(inplace=True)

# ...",7,"The generated code addresses most requirements correctly but has notable issues. 1. **Missing value handling**: It uses `df.dropna(inplace=True)` which removes rows with any missing values, potentially discarding useful data. The ground truth code specifically drops only critical columns (`Global_Sales`, `Year`, `Publisher`, and regional sales), preserving more data. 2. **Years_Since_Release**: It does not handle cases where `Year` exceeds 2023 (e.g., negative values), unlike the ground truth code which uses `max(0, x)`. 3. **Code quality**: Includes unnecessary imports (`matplotlib`, `seaborn`) and lacks error handling for file loading. While it provides comprehensive evaluation (e.g., `classification_report`), the feature importance is visualized instead of directly printed as in the ground truth. These issues reduce correctness and completeness, but the core logic (encoding, model training, and metrics) is sound.",gpt_4o,LLM_judge_config
M12,medium,Feature Engineering and Advanced Analytics,video_games_sales.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import PolynomialFeatures
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Load the dataset
df = pd.read_csv('video_games_sales.csv')

# Handle missing values
df.dropna(inplace=True)

# Feature Engineering

# Sales_Ratio_NA_EU
df['Sales_Ratio_NA_EU'] = df['NA_Sales'] / df['EU_Sales']
df['Sales_Ratio_NA_EU'].repla...",5,"The generated code addresses some aspects of the task but fails to meet several critical requirements. First, it improperly handles missing values by dropping all rows with missing data (`dropna()`), whereas the ground truth uses targeted imputation for specific columns. Second, the code lacks proper handling of division by zero in `Sales_Ratio_NA_EU` (no epsilon added), and it does not explicitly analyze the impact of polynomial features as required. The PCA section omits detailed variance explanation (only cumulative variance is plotted) and incorrectly drops the `Year` column, which is a numerical feature. The interaction features are created using `LabelEncoder`, which is less standard than one-hot encoding. Additionally, the outlier handling aggressively filters rows instead of capping values, leading to data loss. While the code structure is clean, it misses key steps in feature engineering, robustness, and completeness.",gpt_4o,LLM_judge_config
M13,medium,Hypothesis Testing and Statistical Analysis,diabetes.csv,"```python
import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import mannwhitneyu, chi2_contingency, pearsonr, f_oneway

# Load dataset
df = pd.read_csv('diabetes.csv')

# Replace zeros with NaN for specific columns (excluding 'Pregnancies' and 'Outcome')
cols_to_clean = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
df[cols_to_clean] = df[cols_to_clean].replace(0, np.nan)

# Impute missing values with median
df[cols_to_clean] = df[cols_to_clean].fill...",7,"The generated code correctly performs all required statistical tests (t-test, Mann-Whitney U, chi-square, Pearson correlation, ANOVA) and handles data cleaning as specified. However, it lacks detailed output such as test statistics, means, and interpretive explanations for each test, which are critical for a comprehensive analysis. The code does not include error handling for file loading, which the ground truth code explicitly addresses. Additionally, the ANOVA section does not check for empty BMI categories, risking runtime errors if data is missing. While the code is concise and structurally sound, it misses opportunities to provide deeper insights (e.g., contingency tables, descriptive statistics) and fails to fully replicate the thoroughness of the ground truth solution. To improve, add error handling, detailed output (e.g., means, test statistics), and safeguards for edge cases like empty groups.",gpt_4o,LLM_judge_config
M14,medium,Classification and Machine Learning,diabetes.csv,"```python
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    confusion_matrix,
    classification_report,
    roc_...",6,"The generated code addresses most requirements but has several critical shortcomings. 1) **Correctness**: It handles data preprocessing and feature engineering but uses LabelEncoder instead of OneHotEncoder, which can introduce ordinality bias in categorical variables. It also fails to properly handle the 'Age_group' binning (e.g., missing the 0-20 age group). 2) **Code Quality**: The code lacks proper pipelines for preprocessing (e.g., scaling and encoding) and uses a simplistic approach to hyperparameter tuning with limited parameter grids. It also doesn't use cross-validation for all metrics (only ROC-AUC). 3) **Completeness**: While it trains multiple models and evaluates them, it misses comprehensive cross-validation metrics (e.g., accuracy, precision, etc.), doesn't visualize feature importance with proper feature names, and lacks detailed visualizations (e.g., ROC curves for all models in a single plot). The code is functional but lacks the robustness and completeness of the ground truth solution. To improve, it should implement proper preprocessing pipelines, expand hyperparameter grids, and include all required evaluation metrics and visualizations.",gpt_4o,LLM_judge_config
M15,medium,Feature Engineering and Advanced Analytics,diabetes.csv,"```python
import pandas as pd
import numpy as np

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.pi...",7,"The generated code addresses most requirements but has notable gaps. It correctly handles data loading, preprocessing, engineered features, polynomial transformations, scaling, PCA, feature selection (SelectKBest/RFE), correlation filtering, SMOTE, and feature importance visualization. However, it lacks key elements: 1) Polynomial features are applied to fewer columns and original columns are not dropped, leading to redundancy. 2) PCA uses default parameters instead of retaining 95% variance as in the ground truth. 3) Correlation filtering is applied to scaled data rather than raw features, which may affect results. 4) The code doesn't explicitly handle class imbalance in the final evaluation (e.g., no classification report). 5) Some steps (like splitting data before SMOTE) are missing critical implementation details. The code is functional but lacks the comprehensive structure and precision of the ground truth solution.",gpt_4o,LLM_judge_config
M16,medium,Hypothesis Testing and Statistical Analysis,world-happiness-report-2021.csv,"```python
import pandas as pd
import numpy as np
from scipy import stats
import scipy.stats as ss
import seaborn as sns
import matplotlib.pyplot as plt
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Load dataset
df = pd.read_csv('world-happiness-report-2021.csv')

# Handle missing values
df = df.dropna()

# Rename columns for ease of access
df.columns = df.columns.str.strip()
df.columns = df.columns.str.replace(' ', '_')

# 1) Western Europe vs Others: t-test on happiness scores
we...",5,"The generated code has several critical issues. 1) Column name mismatches: It renames columns to use underscores (e.g., 'Regional_indicator' instead of 'Regional indicator') which would cause KeyError if the original dataset uses different naming. 2) Missing error handling: It lacks the FileNotFoundError check present in the ground truth. 3) Incomplete interpretation: It only prints minimal conclusions like ""Significant difference"" without detailed comparisons (e.g., ""HIGHER"" vs ""LOWER""). 4) Quantile approach for GDP test is less precise than the ground truth's sorted slicing method. 5) Unused imports (seaborn, matplotlib, Tukey HSD) reduce code quality. While all required tests are implemented, the fundamental data preparation errors prevent correct execution.",gpt_4o,LLM_judge_config
M17,medium,Regression and Predictive Modeling,world-happiness-report-2021.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Load dataset
df = pd.read_csv(...",7,"The generated code addresses most task requirements, correctly loading the dataset, preprocessing (dropping missing values), creating target/feature variables, training multiple regression models, and implementing hyperparameter tuning and visualizations. However, it fails to first evaluate all models to identify the ""best"" one for hyperparameter tuning (as required in step 5). Instead, it assumes Gradient Boosting is the best model without comparison, which is a critical deviation from the ground truth approach of selecting the top-performing model based on R² score. This affects correctness and completeness. Code quality is good with proper structure and imports, but lacks detailed comments (e.g., explaining why scaling is applied). The residual plot and feature importance are implemented, though they use `residplot` instead of `scatterplot` as in the ground truth. Cross-validation is performed but with a different `cv` value (10 instead of 5). The hypothetical prediction section is functional but uses fewer test cases than the ground truth. These issues reduce the score but the code remains mostly valid.",gpt_4o,LLM_judge_config
M18,medium,Feature Engineering and Advanced Analytics,world-happiness-report-2021.csv,"```python
# Imports
import pandas as pd
import numpy as np
from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot ...",6,"The generated code addresses most of the task requirements but has several critical issues. It lacks visualizations for PCA and t-SNE (missing plt.scatter calls), which were explicitly required. The correlation-based filtering step does not actually drop highly correlated features - it only identifies them without modifying the dataset. The interaction features are incorrectly scaled after being added to the original dataframe, leading to duplication with the polynomial features. The code also omits the 'Regional_GDP_Mean' column drop after creating 'GDP_vs_Regional_Average'. While it implements feature selection methods, it doesn't print the selected features as in the ground truth. The code structure is reasonable but has some inconsistencies in handling feature engineering and scaling steps. Some key requirements like detailed preprocessing and explicit feature selection outputs are not fully implemented.",gpt_4o,LLM_judge_config
M19,medium,Time Series Analysis,synthetic_covid19_data.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Step 1: Load dataset, parse dates, filter for USA
df = pd.read_csv('synthetic_covid19_data.csv', parse_dates=['date'])
usa_df = df[df['location'] == 'USA'].copy()

# Step 2: Set 'date' as index
usa_df.set_index('date', inplace=True)

# Step 3: Resample to weekly frequen...",7,"The generated code correctly addresses most of the task requirements, including loading data, filtering for 'USA', resampling, decomposition, ADF testing, differencing, and ACF/PACF plotting. However, it lacks critical robustness features: 1) No error handling for missing files/data (e.g., if 'synthetic_covid19_data.csv' is missing or USA data is empty). 2) No handling of missing values in 'new_cases' before resampling, which could cause issues. 3) Decomposition uses a fixed period=52 without checking if the data has sufficient length for this period. 4) After differencing, the code doesn't re-validate stationarity (only prints results without action). 5) The ACF/PACF plots use a fixed lag of 40, which might not be optimal for all datasets. While the code is functional, the lack of error handling, adaptive decomposition parameters, and post-differencing validation reduces its completeness compared to the ground truth.",gpt_4o,LLM_judge_config
M2,medium,Statistical Analysis,winequality-red.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Load the dataset
df = pd.read_csv('winequality-red.csv')

# Categorize wines based on pH
def categorize_pH(pH):
    if pH < 3.2:
        return 'Low pH'
    elif pH <= 3.4:
        return 'Medium pH'
    else:
        return 'High pH'

df['pH_group'] = df['pH'].apply(categorize_pH)

# Calculate average quality for each pH group
grouped = df.groupby('pH_group')['quality']
mean_quality = gro...",6,"The generated code addresses most requirements but has critical issues. 1) **Correctness**: The pH categorization is correct, but the confidence interval calculation uses a z-score (1.96) instead of a t-distribution, leading to statistical inaccuracy, especially for small samples. The ANOVA test does not check if groups have sufficient data, risking errors if a group is empty. 2) **Code Quality**: Imports are correct, but the code lacks structured error handling (e.g., missing file checks) and uses a custom function instead of `pd.cut` for categorization, which is less efficient. 3) **Completeness**: The visualization omits text labels on top of bars (as in ground truth) and does not explicitly calculate lower/upper CI bounds. The ANOVA output is minimal, missing detailed interpretation of results. To improve, use `scipy.stats.t.interval` for CI, add checks for group data before ANOVA, and include text annotations on the plot.",gpt_4o,LLM_judge_config
M20,medium,Regression,synthetic_covid19_data.csv,"```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
df = pd.read_csv(""synthetic_covid19_data.csv"", parse_dates=[""date""])

# Select relevant features and target variable
features = [
    'new_cases',
   ...",5,"The generated code has several critical issues. First, it omits the 'continent' feature in the initial selection, violating the task requirement to include it as a feature. Second, it scales the data before splitting into train/test sets, which causes data leakage and violates proper ML workflow. Third, the code imputes missing values for all columns (including categorical 'continent') without excluding it, which is inappropriate. While it correctly performs one-hot encoding, the missing 'continent' in features and scaling before splitting significantly impact model validity. Proper preprocessing order and feature inclusion are essential for accurate evaluation.",gpt_4o,LLM_judge_config
M21,medium,Hypothesis Testing,synthetic_covid19_data.csv,"```python
import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols

# Load dataset
df = pd.read_csv('synthetic_covid19_data.csv')

# Median imputation for relevant columns
columns_to_impute = ['reproduction_rate', 'stringency_index', 'median_age', 'total_deaths', 'population', 'new_cases']
for col in columns_to_impute:
    median_val = df[col].median(skipna=True)
    df[col] = df[col].fillna(median_val)

# Step 2: ANOVA o...",6,"The generated code addresses the main tasks but has critical issues. 1) **Correctness**: The ANOVA uses `statsmodels` but may fail if 'continent' is not properly encoded as a categorical variable (the code assumes it's numeric). The t-test uses 'location' instead of 'country' (as in the ground truth), which could cause incorrect grouping. 2) **Code Quality**: Lacks error handling for missing files/columns, and the ANOVA p-value extraction is brittle (relies on `anova_table['PR(>F)'][0]`, which might not match the actual output structure). 3) **Completeness**: Missing checks for empty groups in the t-test, and no explicit null hypothesis printing (though the output includes it). The code would fail if 'location' differs from 'country' or if 'continent' has unexpected values. Improvements: Use `scipy.stats.f_oneway` for ANOVA, verify column names, add error handling for empty groups, and ensure robust p-value extraction.",gpt_4o,LLM_judge_config
M22,medium,Exploratory Data Analysis (EDA),clash_royale_cards.csv,"```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv('clash_royale_cards.csv')

# Select numerical columns
numeric_cols = ['elixirCost', 'Win Rate', 'Usage', 'Win Rate Change', 'Usage Change']
df_numeric = df[numeric_cols]

# Compute correlation matrix
corr_matrix = df_numeric.corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt="".2f"")
plt.title('Correlation Matrix of Clash Roy...",10,"The generated code correctly loads the dataset, selects the specified numerical columns, computes the pairwise correlation matrix, and visualizes it as a heatmap with all required parameters. It includes proper imports, concise structure, and adheres to the task requirements without unnecessary complexity. The code is complete, accurate, and follows best practices for data analysis workflows. The absence of error handling and a function, while present in the ground truth, is not critical here as the task explicitly stated to ""assume the CSV file is in the current directory"" and did not mandate such robustness. The solution is optimal for the described problem.",gpt_4o,LLM_judge_config
M23,medium,Exploratory Data Analysis (EDA),clash_royale_cards.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# Group by 'rarity' and calculate average of specified columns
averages = df.groupby('rarity')[['elixirCost', 'Win Rate', 'Usage']].mean()

# Display the calculated average values
print(averages)
```",10,"The generated code is fully correct, high-quality, and complete. It properly imports pandas, loads the CSV file from the current directory, groups by the 'rarity' column, calculates the average values for 'elixirCost', 'Win Rate', and 'Usage' using `.mean()`, and displays the results with a `print()` statement. All requirements are met without unnecessary elements. The code is concise, readable, and aligns perfectly with the ground truth solution.",gpt_4o,LLM_judge_config
M24,medium,Feature Engineering,clash_royale_cards.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Load the dataset
df = pd.read_csv('clash_royale_cards.csv')

# Create binary target column
df['is_high_win_rate'] = (df['Win Rate'] > 55).astype(int)

# Select relevant features
features = df[['elixirCost', 'Usage', 'rarity']]
target = df['is_high_win_rate']

# One-hot encode the 'rarity' column
encoder = OneHotEncoder(sparse=False, drop='first')
rarity_encoded = ...",8,"The generated code correctly solves the task with proper steps for loading data, creating the target column, selecting features, and splitting the dataset. The code quality is good, with appropriate imports and structure. However, the use of `OneHotEncoder` with `drop='first'` (default) differs from the ground truth's `pd.get_dummies` with `drop_first=False`, which may result in a different encoding outcome (e.g., dropping the first category vs. retaining all). While both approaches are technically valid, the discrepancy in encoding strategy could affect model performance. Additionally, the code lacks the `try-except` block for file handling, which is a minor but useful addition for robustness. Otherwise, the logic is sound and meets all requirements.",gpt_4o,LLM_judge_config
M25,medium,Classification,iris.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 1. Load the dataset
df = pd.read_csv('iris.csv')

# 2. Define features X
X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]

# 3. Define target y
y = df['Species']

# 4. Encode target variable
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# 5...",10,"The generated code is correct, well-structured, and fully addresses all requirements. It properly loads the dataset, selects the required features and target, encodes the categorical labels, splits the data with the specified 70/30 ratio and random state, trains a KNN classifier with 3 neighbors, and calculates accuracy. All necessary imports are included, and the code is concise. The only minor difference is the absence of error handling for missing files (which the task explicitly allows to assume the CSV exists), but this does not affect correctness. The code meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
M26,medium,Hypothesis Testing,iris.csv,"```python
import pandas as pd
from scipy.stats import ttest_ind

# Load the dataset
df = pd.read_csv('iris.csv')

# Filter the data for the two species
versicolor = df[df['Species'] == 'Iris-versicolor']['PetalLengthCm']
virginica = df[df['Species'] == 'Iris-virginica']['PetalLengthCm']

# State hypotheses
# H0: The mean PetalLengthCm for Iris-versicolor is equal to that for Iris-virginica.
# H1: The mean PetalLengthCm for Iris-versicolor is not equal to that for Iris-virginica.

# Perform the i...",7,"The generated code correctly loads the dataset, filters the two species, performs the t-test, and interprets the result. However, it fails to **print the null and alternative hypotheses explicitly** as required by the task. Instead, the hypotheses are only included as comments, not as output statements. Additionally, while the code uses Welch's t-test (`equal_var=False`), the ground truth assumes equal variances by default. The code lacks structured formatting (e.g., separators, clear labels) for the output, which could improve readability. These minor omissions reduce the completeness score, but the core functionality is correct.",gpt_4o,LLM_judge_config
M27,medium,Data Visualization,iris.csv,"```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv('iris.csv')

# List of numerical features
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

# Create box plots for each feature grouped by Species
for feature in features:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='Species', y=feature, data=df)
    plt.title(f'{feature} by Species')
    plt.xlabel('Species')
    plt.ylabel(feature)
    plt.tight...",10,"The generated code correctly loads the iris.csv dataset, creates four box plots for each numerical feature grouped by 'Species', and includes appropriate titles, labels, and formatting. It uses proper imports (pandas, seaborn, matplotlib) and follows the required structure. The code is concise, meets all task requirements, and produces the expected visualizations. The only minor difference from the ground truth is the absence of explicit error handling, but the task explicitly states to assume the CSV is in the current directory, making error handling optional. The code is clean, efficient, and fully addresses the problem.",gpt_4o,LLM_judge_config
M28,medium,Classification,heart.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score

# Load the dataset
df = pd.read_csv('heart.csv')

# Select features and target
features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Sex', 'ChestPainType']
target = 'HeartDisease'
X = df[features]
y = df[target]

# One-hot encode categorical variables
X_encoded = pd.get...",6,"The generated code correctly loads the data, selects features, and performs one-hot encoding using `pd.get_dummies`. It splits the data and trains a Logistic Regression model, achieving the task's main goals. However, it has a critical flaw: it applies one-hot encoding to the **entire dataset before splitting** into train/test sets, which causes **data leakage** (test set information influences training). The ground truth code properly uses `ColumnTransformer` and a `Pipeline` to ensure preprocessing is applied only to the training set. Additionally, the generated code lacks error handling for file loading (though the task assumes the file exists). The code is functional but violates best practices for data preprocessing, reducing its correctness. To improve, split the data first, then apply encoding to the training set and transform the test set separately.",gpt_4o,LLM_judge_config
M29,medium,Hypothesis Testing,heart.csv,"```python
import pandas as pd
from scipy import stats

# Load the dataset
df = pd.read_csv('heart.csv')

# Create two groups based on the 'Sex' column
males = df[df['Sex'] == 'M']['Cholesterol'].dropna()
females = df[df['Sex'] == 'F']['Cholesterol'].dropna()

# Null Hypothesis (H0): The mean cholesterol levels of male and female patients are equal.
# Alternative Hypothesis (H1): The mean cholesterol levels of male and female patients are not equal.

# Perform independent two-sample t-test
t_stat...",8,"The generated code correctly loads the dataset, splits the data by 'Sex', performs an independent two-sample t-test using Welch's method (equal_var=False), and interprets the results based on alpha=0.05. The hypotheses are clearly stated with proper terminology (H0 and H1). However, it lacks error handling for file loading and missing columns, which are present in the ground truth code. Additionally, it does not include the sample size printouts or the structured function with a docstring. These omissions reduce completeness but do not affect the core functionality. The code is concise and adheres to the task requirements, with good variable naming and necessary imports.",gpt_4o,LLM_judge_config
M3,medium,Data Preprocessing,winequality-red.csv,"```python
import pandas as pd
import numpy as np

# Load dataset
df = pd.read_csv('winequality-red.csv')

# Columns to check for outliers
columns = ['volatile acidity', 'residual sugar']

# Initialize dictionaries to store stats
outlier_counts = {}
original_stats = {}
winsorized_stats = {}

# Create a copy for winsorization
df_winsorized = df.copy()

for col in columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bo...",9,"The generated code correctly identifies outliers using the IQR method, performs winsorization, and compares mean and standard deviation before/after treatment. It meets all task requirements with proper imports and structure. The code is concise and functional, though it lacks detailed intermediate output (e.g., Q1/Q3/IQR values) and error handling for missing files, which were included in the ground truth but not required by the task. The winsorization logic is correct, and the statistics comparison is properly implemented. To improve further, adding error handling or more detailed reporting would align more closely with the ground truth's thoroughness, but the code is otherwise robust and task-compliant.",gpt_4o,LLM_judge_config
M30,medium,Data Visualization,heart.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('heart.csv')

# Create a count plot with hue for HeartDisease
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='ChestPainType', hue='HeartDisease')

# Add title and labels
plt.title('Heart Disease Count by Chest Pain Type')
plt.xlabel('Chest Pain Type')
plt.ylabel('Count')
plt.legend(title='Heart Disease')

# Show the plot
plt.tight_layout()
plt.show()
```",7,"The generated code correctly loads the dataset and creates a grouped bar chart using seaborn's countplot with appropriate labels, title, and legend. However, it lacks some details from the ground truth: 1) It does not map HeartDisease values (0/1) to descriptive labels (e.g., ""No Heart Disease"" vs. ""Heart Disease""), which improves readability. 2) It does not enforce the specific order of ChestPainType categories (TA, ATA, NAP, ASY), which could lead to inconsistent plotting. 3) It omits error handling for file operations, though the task assumes the CSV is present. The code is concise and meets core requirements but misses refinements for clarity and robustness.",gpt_4o,LLM_judge_config
M31,medium,Data Cleaning,spotify_2023.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('spotify_2023.csv')

# Clean 'in_shazam_charts' column
df['in_shazam_charts'] = df['in_shazam_charts'].astype(str).str.replace(',', '')
df['in_shazam_charts'] = pd.to_numeric(df['in_shazam_charts'], errors='coerce')

# Report count of NaNs in 'in_shazam_charts'
nan_count = df['in_shazam_charts'].isna().sum()
print(f""Number of NaNs in 'in_shazam_charts': {nan_count}"")

# Group by 'key' and 'mode', and calculate averages
grouped = ...",10,"The generated code fully meets all requirements. It correctly loads the dataset, cleans the `in_shazam_charts` column by removing commas and converting to numeric with coercion, reports NaN counts accurately, groups by `key` and `mode`, and calculates the required averages. The code is concise, well-structured, and includes proper imports. The only minor difference from the ground truth is the absence of explicit error handling for missing files, but the task explicitly states to assume the CSV is in the current directory, making this omission non-critical. The code is functionally identical to the ground truth and adheres to best practices.",gpt_4o,LLM_judge_config
M32,medium,Regression,spotify_2023.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Load dataset
df = pd.read_csv('spotify_2023.csv')

# Ensure 'streams' is numeric, coerce errors to NaN
df['streams'] = pd.to_numeric(df['streams'], errors='coerce')

# Drop rows with NaN in 'streams', 'in_spotify_playlists', 'energy_%'
df = df.dropna(subset=['streams', 'in_spotify_playlists', 'energy_%'])
...",10,"The generated code correctly solves the task with proper implementation. It loads the dataset, ensures the `streams` column is numeric, drops rows with NaN values in required columns, selects the correct features and target, splits the data, trains a Linear Regression model, and evaluates it with R2 and MSE. The code is concise, well-structured, and includes all necessary imports. While it lacks explicit error handling for file not found (which the task allows to assume the file exists), it meets all required criteria without unnecessary complexity. The code is efficient and adheres strictly to the problem's instructions.",gpt_4o,LLM_judge_config
M33,medium,Feature Engineering,spotify_2023.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('spotify_2023.csv')

# Combine released_year, released_month, and released_day into a datetime column
df['release_date'] = pd.to_datetime(
    df[['released_year', 'released_month', 'released_day']],
    errors='coerce'
)

# Create days_since_release compared to fixed date '2023-12-31'
fixed_date = pd.Timestamp('2023-12-31')
df['days_since_release'] = (fixed_date - df['release_date']).dt.days

# Display track_name, release_date, ...",7,"The generated code correctly loads the dataset, combines the date components into a datetime column with `errors='coerce'` to handle invalid dates, and calculates `days_since_release` as the difference from '2023-12-31'. However, it fails to explicitly convert the `days_since_release` column to a nullable integer type (`Int64`), leaving it as a float (which can contain NaN values for NaT entries). This violates the task's requirement for the feature to be an integer. Additionally, while the date combination approach using `pd.to_datetime(df[['...']])` works, the ground truth's method of explicitly formatting the date string with zero-padding ensures more robust parsing. The code lacks error handling for file loading, but the task assumes the CSV is in the current directory, so this is not critical. Improving data type handling and adding zero-padding for month/day values would enhance reliability.",gpt_4o,LLM_judge_config
M34,medium,Data Cleaning & Aggregation,youtube_trendings.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# Clean 'Video views' and 'Likes' columns
for col in ['Video views', 'Likes']:
    df[col] = df[col].astype(str).str.replace(',', '', regex=True)
    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

# Fill missing values in 'Category' column
df['Category'] = df['Category'].fillna('Unknown')

# Group by 'Category' and calculate the sum of 'Video views' and 'Likes'
result = df.groupby('Category...",7,"The generated code correctly addresses the core requirements by loading the dataset, cleaning the 'Video views' and 'Likes' columns (removing commas, converting to numeric, filling NaNs with 0), filling missing 'Category' values with 'Unknown', and grouping to calculate sums. However, it lacks robustness by not checking for the existence of required columns (e.g., 'Video views', 'Likes', 'Category') before processing, which could lead to runtime errors if the CSV structure differs from expectations. Additionally, it omits error handling for file loading (e.g., `FileNotFoundError`) and does not include warnings or structured error messages for missing columns, as seen in the ground truth code. These omissions reduce its reliability in real-world scenarios. The code is concise and well-structured otherwise, demonstrating good Python practices.",gpt_4o,LLM_judge_config
M35,medium,Hypothesis Testing,youtube_trendings.csv,"```python
import pandas as pd
from scipy import stats

# 1. Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# 2. Clean the 'Likes' column
df['Likes'] = df['Likes'].astype(str).str.replace(',', '', regex=False)
df['Likes'] = pd.to_numeric(df['Likes'], errors='coerce')
df['Likes'] = df['Likes'].fillna(0)

# 3. Fill missing values in 'Category' column
df['Category'] = df['Category'].fillna('Unknown')

# 4. Create two groups of Likes values
music_likes = df[df['Category'] == 'Music']['Li...",7,"The generated code correctly loads the dataset, cleans the 'Likes' column, fills missing 'Category' values, and performs the t-test. However, it fails to explicitly print the hypotheses as required (they are in comments instead of printed output) and omits the check for sufficient sample size in the groups. Additionally, the original 'Likes' column is modified directly rather than creating a new cleaned column, which could be considered a minor deviation from the ground truth's approach. These gaps affect completeness and clarity, but the core logic is sound.",gpt_4o,LLM_judge_config
M36,medium,Feature Engineering,youtube_trendings.csv,"```python
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('youtube_trendings.csv')

# Clean 'Likes' column
df['Likes'] = df['Likes'].astype(str).str.replace(',', '')
df['Likes'] = pd.to_numeric(df['Likes'], errors='coerce').fillna(0)

# Clean 'Dislikes' column
df['Dislikes'] = df['Dislikes'].astype(str).str.replace(',', '')
df['Dislikes'] = pd.to_numeric(df['Dislikes'], errors='coerce').fillna(0)

# Create 'TotalEngagement' column
df['TotalEngagement'] = df['Likes'] +...",10,"The generated code correctly solves the task with all required steps addressed. It properly loads the dataset, cleans the 'Likes' and 'Dislikes' columns by removing commas, converting to numeric (with error coercion and NaN filling), creates 'TotalEngagement' as the sum of cleaned likes/dislikes, and calculates 'LikeDislikeRatio' with denominator +1. Imports are correct (pandas is used, and numpy is not needed but not harmful). The code is concise, complete, and matches the ground truth in functionality. No critical errors or missing requirements.",gpt_4o,LLM_judge_config
M37,medium,Data Aggregation,mobiles_2025.csv,"```python
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('mobiles_2025.csv')

# Clean 'Launched Price (USA)' column
df['Launched Price (USA)'] = df['Launched Price (USA)'] \
    .str.replace('USD ', '', regex=False) \
    .str.replace(',', '', regex=False)
df['Launched Price (USA)'] = pd.to_numeric(df['Launched Price (USA)'], errors='coerce')

# Clean 'Screen Size' column
df['Screen Size'] = df['Screen Size'] \
    .str.replace(' inches', '', regex=False)
df['Screen ...",7,"The generated code is mostly correct but has two critical issues. First, it does not explicitly convert the 'Launched Price (USA)' and 'Screen Size' columns to string type before applying the replace operations, which could cause errors if the original data contains non-string values (e.g., numbers or NaNs). Second, it includes an unnecessary import of numpy. While the code correctly cleans the columns, groups by 'Company Name' and 'Launched Year', calculates averages, and displays the result, the lack of string conversion makes it less robust. Additionally, the code omits error handling for file loading, which the ground truth includes but the task explicitly states to assume the CSV is in the current directory. These issues reduce its correctness and code quality.",gpt_4o,LLM_judge_config
M38,medium,Feature Engineering,mobiles_2025.csv,"```python
import pandas as pd
import re

# Load the dataset
df = pd.read_csv('mobiles_2025.csv')

# Function to extract first sequence of digits as MP value
def extract_mp(camera_str):
    if pd.isnull(camera_str):
        return 0
    match = re.search(r'\d+', camera_str)
    return int(match.group()) if match else 0

# Apply function to clean camera columns
df['Cleaned Front Camera'] = df['Front Camera'].apply(extract_mp)
df['Cleaned Back Camera'] = df['Back Camera'].apply(extract_mp)

# Creat...",8,"The generated code correctly loads the dataset, extracts MP values from camera specifications, creates the required features, and displays the first 10 rows. It properly uses regex to extract the first sequence of digits and handles null values with `pd.isnull`. However, it lacks error handling for file loading (missing try-except block) and doesn't explicitly convert non-string inputs to strings before processing, which could cause issues if the dataset contains non-string values in camera columns. The code is concise and meets most requirements, but adding file validation and input type conversion would improve robustness. The output formatting is functional but less polished than the ground truth's use of `.to_string()`.",gpt_4o,LLM_judge_config
M39,medium,Regression,mobiles_2025.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error

# Load dataset
df = pd.read_csv('mobiles_2025.csv')

# Clean RAM
df['RAM'] = pd.to_numeric(df['RAM'].str.replace('GB', '', regex=False), errors='coerce')

# Clean Battery Capacity
df['Battery Capacity'] = pd.to_numeric(df['Battery Capacity'].str.replace('mAh', '', regex=False), errors='coerce')

# Clean Scr...",10,"The generated code correctly solves the task with high code quality and completeness. It properly loads the dataset, cleans all specified columns by removing units and converting to numeric (using `pd.to_numeric` with `errors='coerce'`), drops rows with NaNs in the cleaned columns, defines features and target as required, splits the data with `random_state=42`, trains a Linear Regression model, and calculates R2 and MAE. The code is concise, directly addresses all requirements, and includes necessary imports. The only minor difference from the ground truth is the absence of explicit column existence checks and file-not-found handling, but the task explicitly states to assume the CSV is present, making these omissions non-critical. The solution is robust, well-structured, and meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
M4,medium,Hypothesis Testing,titanic.csv,"```python
import pandas as pd
import numpy as np
from scipy import stats

# Load dataset
df = pd.read_csv('titanic.csv')

# Set alpha level
alpha = 0.05

# 1) Chi-square test between Pclass and Survival
chi_data = df[['Pclass', 'Survived']].dropna()
contingency_table = pd.crosstab(chi_data['Pclass'], chi_data['Survived'])
chi2, p_chi, dof, expected = stats.chi2_contingency(contingency_table)

# Calculate Cramér's V for effect size
n = contingency_table.sum().sum()
phi2 = chi2 / n
r, k = continge...",6,"The generated code correctly performs the chi-square test, t-test, and ANOVA, and calculates the required effect sizes (Cramér's V, Cohen's d, and eta-squared). However, it **misses critical statistical methodology steps** required by the task. Specifically:  
1. The t-test and ANOVA sections omit **Levene's test for variance equality**, which is essential for determining whether to use Welch's t-test or a standard ANOVA. This violates the task's requirement to ""properly perform statistical methodology"" and may lead to incorrect conclusions if variances are unequal.  
2. The code lacks **error handling** for cases where groups (e.g., Pclass 1/2/3 or Survived/Non-Survived) might become empty after dropping missing values, which could cause runtime errors.  
3. While effect sizes are calculated, the **interpretation of their magnitudes** (e.g., what values of Cramér's V, Cohen's d, or eta-squared imply) is missing, though the task explicitly required ""interpret effect sizes.""  
4. The code does not explicitly display the test statistics and p-values in the same structured format as the ground truth (e.g., no separation of results with consistent formatting or detailed hypothesis statements).  
To improve, include Levene's tests, handle edge cases (e.g., empty groups), and add explicit effect size interpretation.",gpt_4o,LLM_judge_config
M40,medium,Time Series EDA,imdb_top_250.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# Group by 'Year' and calculate average Rating and Runtime
yearly_avg = df.groupby('Year')[['Rating', 'Runtime']].mean().reset_index()

# Sort by Year to ensure correct plotting
yearly_avg = yearly_avg.sort_values('Year')

# Plot average Rating over Year
plt.figure(figsize=(10, 6))
plt.plot(yearly_avg['Year'], yearly_avg['Rating'], marker='o')
plt.title('Average IMDb Rating by ...",9,"The generated code correctly loads the dataset, groups by 'Year', calculates the average 'Rating' and 'Runtime', and creates a line plot with appropriate labels and title. It follows proper structure with necessary imports and uses `groupby` and `mean` effectively. The only minor omission is the lack of explicit handling for potential non-numeric values in 'Year' or 'Runtime' columns, which the ground truth code includes. However, since the task assumes the CSV is in the current directory and does not explicitly require data cleaning, this is not critical. The code is concise, complete, and meets all stated requirements. Strong points include clarity, direct execution, and proper visualization setup.",gpt_4o,LLM_judge_config
M41,medium,Hypothesis Testing,imdb_top_250.csv,"```python
import pandas as pd
from scipy import stats

# 1) Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# 2) Create two groups based on Year
group_before_1990 = df[df['Year'] < 1990]['Rating']
group_1990_or_later = df[df['Year'] >= 1990]['Rating']

# 3) Perform independent two-sample t-test
t_statistic, p_value = stats.ttest_ind(group_before_1990, group_1990_or_later, equal_var=False)

# 4) Hypotheses
print(""Null hypothesis: The mean Ratings of movies released before 1990 and in/after...",7,"The generated code addresses the core task but lacks critical data validation steps. It doesn't convert the 'Year' and 'Rating' columns to numeric types or handle potential conversion errors, which could cause runtime issues if the CSV contains non-numeric values. It also omits checks for sufficient sample sizes (minimum 2 samples per group) before performing the t-test, which is essential for statistical validity. While the hypotheses are correctly stated, they are less formalized than the ground truth's explicit wording. The code uses Welch's t-test (equal_var=False) by default, which is acceptable but not explained. The output formatting is simpler than the ground truth's structured presentation, though the statistical interpretation is logically sound. To improve, add data type validation, missing value handling, and group size checks.",gpt_4o,LLM_judge_config
M42,medium,Feature Engineering,imdb_top_250.csv,"```python
import pandas as pd

# 1. Load the dataset
df = pd.read_csv('imdb_top_250.csv')

# 2. Create 'Decade' column
df['Decade'] = (df['Year'] // 10 * 10).astype(str) + 's'

# 3. Display 'Title', 'Year', 'Decade' for first 10 movies
print(df[['Title', 'Year', 'Decade']].head(10))
```",6,"The generated code correctly loads the dataset, creates the 'Decade' column using integer division and string formatting, and displays the first 10 movies with the required columns. However, it lacks critical components from the ground truth: 1) No error handling for file or data issues (e.g., missing columns, non-numeric years). 2) Does not clean the 'Year' column (e.g., converting to numeric, handling NaNs, or ensuring integer type). 3) No modularity (no function for feature engineering). While the core logic is correct, these omissions reduce robustness and code quality. To improve, add data validation, error handling, and structured functions as in the ground truth.",gpt_4o,LLM_judge_config
M43,medium,Data Cleaning,penguins.csv,"```python
import pandas as pd

# Load the dataset
df = pd.read_csv(""penguins.csv"")

# Impute numerical columns with mean
numerical_cols = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
for col in numerical_cols:
    mean_value = df[col].mean(skipna=True)
    df[col].fillna(mean_value, inplace=True)

# Impute categorical 'sex' column with mode
mode_value = df['sex'].mode(dropna=True)[0]
df['sex'].fillna(mode_value, inplace=True)

# Group by 'species' and 'sex' and cal...",9,"The generated code correctly loads the dataset, imputes missing values for numerical columns using means and the 'sex' column using mode, groups by 'species' and 'sex', and calculates the average body_mass_g. It is concise, well-structured, and uses proper pandas functions. The code meets all task requirements except for two minor points: it lacks error handling (e.g., FileNotFoundError) present in the ground truth and omits the explicit `pd.to_numeric()` conversion for body_mass_g, though this is not strictly necessary if the column is already numeric. These omissions are minor and do not affect correctness under the task's assumptions. The code demonstrates strong quality and completeness.",gpt_4o,LLM_judge_config
M44,medium,Hypothesis Testing,penguins.csv,"```python
import pandas as pd
from scipy import stats

# Step 1: Load the dataset
df = pd.read_csv('penguins.csv')

# Step 2: Filter species to 'Adelie' or 'Gentoo'
df_filtered = df[df['species'].isin(['Adelie', 'Gentoo'])]

# Step 3: Drop rows with missing 'flipper_length_mm' or 'species'
df_filtered = df_filtered.dropna(subset=['flipper_length_mm', 'species'])

# Step 4: Separate the data by species
adelie_flipper = df_filtered[df_filtered['species'] == 'Adelie']['flipper_length_mm']
gentoo_fl...",6,"The generated code correctly performs the t-test and addresses most core requirements but misses critical elements. 1) **Correctness**: It lacks error handling for file loading (missing try-except blocks) and data sufficiency checks (e.g., empty groups after filtering). 2) **Code quality**: It omits proper imports (no explicit import of `stats` as in the ground truth), does not use `.copy()` when filtering data (risking `SettingWithCopyWarning`), and uses comments instead of printed hypotheses. 3) **Completeness**: It does not explicitly print dataset shapes after filtering/NA removal, nor does it state hypotheses in the output (only as comments). Additionally, the interpretation lacks detailed context (e.g., ""fail to reject"" vs. ""reject"" wording is less rigorous than the ground truth). To improve, add error handling, explicit hypothesis printing, data validation checks, and use `.copy()` where applicable.",gpt_4o,LLM_judge_config
M45,medium,Classification,penguins.csv,"```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load dataset
data = pd.read_csv('penguins.csv')

# Select features and target
features = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
target = 'species'

# Drop rows with missing values in selected columns
data_clean = data.dropna(subset=fea...",10,"The generated code successfully fulfills all task requirements with correct implementation. It properly loads the dataset, selects the specified features and target, drops rows with missing values, encodes the target variable, splits the data with 80/20 ratio and random_state=42, trains a Logistic Regression model with max_iter=1000, and calculates accuracy. The code is concise, well-structured, and includes all necessary imports. While it lacks some error handling (e.g., column existence checks) present in the ground truth code, the task explicitly assumes the CSV file is in the current directory and columns exist. The code is functionally identical to the ground truth in terms of core requirements and demonstrates excellent code quality.",gpt_4o,LLM_judge_config
M46,medium,Exploratory Data Analysis (EDA),penguins.csv,"```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load the dataset
df = pd.read_csv('penguins.csv')

# 2. Drop rows where 'body_mass_g' or 'species' is NA
df_clean = df.dropna(subset=['body_mass_g', 'species'])

# 3. Calculate average body_mass_g for each species
avg_mass = df_clean.groupby('species')['body_mass_g'].mean().reset_index()

# 4. Create a bar plot
plt.figure(figsize=(8,6))
sns.barplot(data=avg_mass, x='species', y='body_mass_g', palette='virid...",9,"The generated code correctly solves the task with concise and proper implementation. It loads the dataset, drops NA rows for the required columns, calculates average body mass per species, and creates a labeled bar plot. The code quality is good with proper imports and structure. The only minor omission is the lack of error handling for file loading (though the task assumes the CSV is present), and the plot title is hardcoded instead of dynamically generated. These are minor issues, and the code fully meets the evaluation criteria.",gpt_4o,LLM_judge_config
M47,medium,Feature Engineering,penguins.csv,"```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load the dataset
df = pd.read_csv('penguins.csv')

# 2. Drop rows with NA in specified columns
df = df.dropna(subset=['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'])

# 3. Create a new feature 'culmen_area'
df['culmen_area'] = df['culmen_length_mm'] * df['culmen_depth_mm']

# 4. Calculate the Pearson correlation matrix
features = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_l...",9,"The generated code correctly performs all required tasks: loading the dataset, dropping rows with NA in specified columns, creating the `culmen_area` feature, calculating the Pearson correlation matrix, and visualizing it as an annotated heatmap. It is concise and follows proper Python syntax with correct imports. However, it lacks a few best practices from the ground truth code, such as using `.copy()` after `dropna()` to avoid `SettingWithCopyWarning` and explicitly checking for empty data after cleaning. Additionally, while the heatmap visualization is accurate, the ground truth includes more detailed layout adjustments (e.g., rotating x-axis labels). Despite these minor omissions, the code fully satisfies the task requirements and is functionally sound.",gpt_4o,LLM_judge_config
M48,medium,Feature Engineering,penguins.csv,"```python
import pandas as pd

# 1. Load dataset
df = pd.read_csv('penguins.csv')

# 2. Select features and target
features = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g', 'island', 'sex']
target = 'species'
df = df[features + [target]]

# 3. Impute numerical features with column mean
numerical_features = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']
df[numerical_features] = df[numerical_features].apply(lambda col: col.fillna(col.mean()...",6,"The generated code addresses the core task but has critical omissions. 1) It lacks error handling for missing files (no try-except block), which the ground truth includes. 2) It doesn't use `.copy()` when selecting features, risking `SettingWithCopyWarning`. 3) The `sex` column mapping assumes all values are 'MALE', 'FEMALE', or 'Unknown' without checking for unexpected values, which could cause errors. 4) The code doesn't explicitly handle cases where `sex` might have mixed data types (e.g., non-string values). 5) While it performs one-hot encoding correctly, it doesn't include the (optional) target variable value counts print. The code is concise but misses robustness checks and safety practices present in the ground truth.",gpt_4o,LLM_judge_config
M49,medium,Customer Segmentation,,"```python
import pandas as pd

# Create DataFrame
data = {
    'OrderID': [101, 102, 103, 104, 105, 106, 107],
    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam', 'Mouse', 'Laptop'],
    'Category': ['Electronics'] * 7,
    'Quantity': [1, 2, 1, 1, 3, 1, 1],
    'Price_USD': [1200, 25, 75, 300, 50, 25, 1150],
    'CustomerID': ['CUST001', 'CUST002', 'CUST001', 'CUST003', 'CUST002', 'CUST004', 'CUST001']
}

df = pd.DataFrame(data)

# Calculate amount spent per order
df['Total_Spen...",9,"The generated code correctly creates the DataFrame, calculates total spending per customer, identifies the top 3 customers, and computes total quantity per category. It is concise, uses proper pandas syntax, and includes necessary imports. The only minor oversight is the absence of detailed print formatting (e.g., specific messages like ""Top 3 Customers by Total Spending (Descending Order):"") and explicit error handling for edge cases (e.g., empty data), which are present in the ground truth but not required by the task. The code effectively addresses all functional requirements with clean, efficient logic.",gpt_4o,LLM_judge_config
M5,medium,Classification,titanic.csv,"```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    classification_report,
)

# Load dataset
df = pd...",5,"The generated code partially addresses the task but has critical issues. 1) **Data Preprocessing**: It incorrectly scales the entire dataset before splitting, causing data leakage. It also omits 'Pclass' (treated as categorical in the ground truth) and skips feature engineering (FamilySize). 2) **Model Training**: While it uses LogisticRegression, it lacks a pipeline, making preprocessing and scaling less reproducible. 3) **Evaluation Metrics**: Metrics are calculated correctly but missing detailed interpretation of coefficients. 4) **Visualizations**: Confusion matrix and ROC curve are present but less polished than the ground truth's use of dedicated display classes. 5) **Cross-Validation**: Only accuracy is evaluated, not all required metrics (precision, recall, F1, ROC AUC). The code structure is functional but violates best practices (scaling before split) and misses key requirements like feature engineering and comprehensive cross-validation.",gpt_4o,LLM_judge_config
M50,medium,Time Series Analysis,,"```python
import pandas as pd

# Create the initial DataFrame
data = {
    'Date': pd.to_datetime([
        '2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04',
        '2024-01-05', '2024-01-08', '2024-01-09', '2024-01-10'
    ]),
    'Ticker': ['TECHCO'] * 8,
    'Open': [150.0, 152.5, 151.0, 153.0, 155.5, 154.0, 156.0, 155.0],
    'High': [153.0, 153.5, 154.0, 156.0, 157.0, 156.5, 157.5, 156.5],
    'Low': [149.5, 150.5, 150.0, 152.5, 154.5, 153.0, 155.0, 154.0],
    'Close': [152.0, 151.0...",7,"The generated code correctly creates the DataFrame with 'Date' as the index and calculates the 3-day SMA for 'Close' using `rolling(window=3).mean()`, which handles NaNs appropriately. However, it incorrectly multiplies the 'Volume_Pct_Change' by 100, whereas the ground truth code uses `pct_change()` without scaling. This results in values being 100x larger than expected, which is a critical error for correctness. The code also lacks the descriptive print message present in the ground truth, though the task only explicitly required printing the DataFrame. While the structure and imports are clean, the percentage change scaling discrepancy and missing print message reduce the score. Improvements would include removing the `*100` and adding the print header for alignment with the ground truth.",gpt_4o,LLM_judge_config
M51,medium,Data Transformation & Analysis,,"```python
import pandas as pd

# Create the DataFrame
data = {
    'StudentID': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008', 'S009', 'S010'],
    'Subject': ['Math', 'Science', 'Math', 'English', 'Science', 'Math', 'English', 'Science', 'Math', 'English'],
    'Midterm_Score': [85, 92, 78, 88, 76, 95, 82, 89, 70, 91],
    'Final_Score': [90, 88, 82, 92, 80, 91, 85, 93, 75, 89],
    'Attendance_Rate': [0.95, 0.98, 0.85, 0.92, 0.80, 0.99, 0.88, 0.96, 0.75, 0.93]
}
df = pd.DataF...",10,"The generated code correctly solves the task with high code quality and completeness. It properly creates the DataFrame, calculates the 'Score_Improvement' column as required, computes average improvements per subject using `groupby`, and identifies students meeting the criteria with accurate filtering. The code is concise, uses pandas effectively, and includes necessary imports. While it omits the explicit print statements for the original DataFrame and separators present in the ground truth, these are not required by the task. The student ID output format is valid (using `to_list()`), and all logic is correct. The code meets all evaluation criteria without unnecessary complexity.",gpt_4o,LLM_judge_config
M52,medium,Data Manipulation,,"```python
import pandas as pd

# Define the data
data = {
    ""EmployeeID"": [""E001"", ""E002"", ""E003"", ""E004"", ""E005"", ""E006"", ""E007"", ""E008""],
    ""Department"": [""Sales"", ""HR"", ""Tech"", ""Sales"", ""Tech"", ""HR"", ""Tech"", ""Sales""],
    ""PerformanceScore"": [4, 3, 5, 2, 4, 3, 5, 4],
    ""YearsExperience"": [5, 2, 8, 3, 6, 2, 10, 4],
    ""ProjectsCompleted"": [10, 5, 15, 4, 12, 6, 20, 8],
    ""TrainingHours"": [20, 40, 10, 50, 20, 30, 15, 25]
}

# Create the DataFrame
df = pd.DataFrame(data)

# Filter for Te...",8,"The generated code correctly defines the DataFrame with the specified data and accurately filters for ""Tech"" department employees with a ""PerformanceScore"" greater than 3. It also calculates and prints the average ""ProjectsCompleted"" as required. However, it lacks a check for empty filtered results, which the ground truth code includes to handle edge cases (e.g., if no employees met the criteria). While the code works for the provided dataset, adding this conditional check would improve robustness and completeness. The code structure and formatting are clean, and all requirements are addressed except for the edge-case handling.",gpt_4o,LLM_judge_config
M53,medium,Data Manipulation,,"```python
import pandas as pd

# Create DataFrame
data = {
    ""UserID"": [""User1"", ""User2"", ""User3"", ""User4"", ""User5"", ""User6""],
    ""SessionDurationMinutes"": [15, 25, 10, 30, 22, 18],
    ""PagesViewed"": [5, 8, 3, 10, 7, 6],
    ""DeviceType"": [""Desktop"", ""Mobile"", ""Desktop"", ""Mobile"", ""Desktop"", ""Mobile""],
    ""Converted"": [True, False, False, True, True, False]
}
df = pd.DataFrame(data)

# Calculate conversion rates
desktop_users = df[df[""DeviceType""] == ""Desktop""]
mobile_users = df[df[""DeviceT...",8,"The generated code correctly defines the DataFrame and calculates the conversion rates for Desktop and Mobile users as required. It uses a straightforward approach by filtering the DataFrame and computing the conversion rate via sum divided by length, which is mathematically valid. However, it lacks error handling for edge cases (e.g., if there are no Desktop or Mobile users, which would cause a ZeroDivisionError). The ground truth code includes these safeguards, but the generated code assumes the data is non-empty. The code quality is good, with proper structure and clear variable names. To improve, adding checks for empty DataFrames and handling division by zero would make it more robust. The print statements are also correctly labeled.",gpt_4o,LLM_judge_config
M54,medium,Data Aggregation,,"```python
import pandas as pd

# Define the data
data = {
    ""Timestamp"": [""2025-05-24 10:00"", ""2025-05-24 10:05"", ""2025-05-24 10:10"", ""2025-05-24 10:15"", ""2025-05-24 10:00"", ""2025-05-24 10:05""],
    ""SensorID"": [""S1"", ""S1"", ""S1"", ""S1"", ""S2"", ""S2""],
    ""TemperatureCelsius"": [22.5, 22.7, 22.6, 22.8, 21.9, 22.0],
    ""HumidityPercent"": [55, 56, 55, 57, 60, 59],
    ""AirQualityIndex"": [30, 32, 31, 33, 25, 26]
}

# Create the DataFrame
df = pd.DataFrame(data)

# Calculate and print average AirQual...",10,"The generated code fully meets all requirements. It correctly defines the DataFrame with the specified data structure, groups by ""SensorID"" to calculate the average ""AirQualityIndex"", and prints the results with clear labeling. The code is concise, properly structured, and uses appropriate pandas operations. The formatting of the average values to two decimal places ensures readability, and the output explicitly associates each average with its corresponding SensorID. All critical task elements are addressed without unnecessary complexity.",gpt_4o,LLM_judge_config
M55,medium,Feature Engineering & Filtering,,"```python
import pandas as pd

# Define the data
data = {
    ""PostID"": [""SM01"", ""SM02"", ""SM03"", ""SM04"", ""SM05"", ""SM06""],
    ""Platform"": [""Instagram"", ""Twitter"", ""Facebook"", ""Instagram"", ""Twitter"", ""Instagram""],
    ""PostType"": [""Image"", ""Text"", ""Video"", ""Image"", ""Text"", ""Video""],
    ""Likes"": [150, 80, 300, 200, 90, 450],
    ""Shares"": [20, 15, 50, 30, 10, 60],
    ""Comments"": [10, 5, 25, 15, 8, 30]
}

# Create the DataFrame
df = pd.DataFrame(data)

# Step 1: Create EngagementScore
df[""Engagem...",9,"The generated code correctly defines the DataFrame, calculates the ""EngagementScore"" using the specified formula, filters for Instagram posts, and computes their average engagement score. It is concise, well-structured, and follows proper Python and pandas conventions. The only minor omission is the absence of a check for empty DataFrames when calculating the mean (as seen in the ground truth code), which could prevent potential errors in edge cases. However, this is not critical for the given task since the dataset explicitly contains Instagram posts. The code is otherwise complete, correct, and efficient.",gpt_4o,LLM_judge_config
M56,medium,Data Manipulation,,"```python
import pandas as pd

# Create the DataFrame
data = {
    ""PatientID"": [""P001"", ""P002"", ""P003"", ""P004"", ""P005"", ""P006""],
    ""AdmissionDate"": pd.to_datetime([""2025-01-10"", ""2025-01-12"", ""2025-01-15"", ""2025-01-18"", ""2025-01-20"", ""2025-01-22""]),
    ""DischargeDate"": pd.to_datetime([""2025-01-15"", ""2025-01-16"", ""2025-01-22"", ""2025-01-25"", ""2025-01-24"", ""2025-01-28""]),
    ""Diagnosis"": [""Flu"", ""Cold"", ""Flu"", ""Injury"", ""Cold"", ""Flu""],
    ""Age"": [34, 56, 23, 45, 67, 30],
    ""Gender"": [""Male""...",9,"The generated code correctly defines the DataFrame, calculates the ""LengthOfStay"" column, filters for ""Flu"" patients, and computes their average length of stay. It is concise and adheres to the task requirements. The only minor omission is the absence of intermediate print statements to verify DataFrame structure (as seen in the ground truth), but the task explicitly required only the code to solve the problem, not additional diagnostics. The code is well-structured, uses proper pandas operations, and avoids common pitfalls like unnecessary warnings. The average calculation is accurate and correctly formatted for output. A high-quality solution with only minor room for improvement in explicit verification steps.",gpt_4o,LLM_judge_config
M57,medium,Data Filtering & Aggregation,,"```python
import pandas as pd

# Define the data
data = {
    ""MovieID"": [""M01"", ""M02"", ""M03"", ""M04"", ""M05"", ""M06""],
    ""Title"": [""Inception"", ""The Dark Knight"", ""Pulp Fiction"", ""Forrest Gump"", ""The Matrix"", ""Interstellar""],
    ""Genre"": [""Sci-Fi"", ""Action"", ""Crime"", ""Drama"", ""Sci-Fi"", ""Sci-Fi""],
    ""Year"": [2010, 2008, 1994, 1994, 1999, 2014],
    ""Rating"": [8.8, 9.0, 8.9, 8.8, 8.7, 8.6],
    ""Votes"": [2200000, 2500000, 1900000, 1800000, 1700000, 1600000]
}

# Create the DataFrame
df = pd.Dat...",10,"The generated code correctly defines the DataFrame with all specified columns and data. It accurately filters for ""Sci-Fi"" movies using boolean indexing and calculates the average rating without errors. The code is concise, well-structured, and adheres to Python best practices. While it lacks the edge-case handling for empty DataFrames present in the ground truth, this is not critical for the task as the dataset explicitly contains Sci-Fi movies. The print statement is functional and meets the requirement to output the average rating. The code is fully correct, complete, and of high quality.",gpt_4o,LLM_judge_config
M58,medium,Data Manipulation,,"```python
import pandas as pd

# Define the DataFrame
data = {
    ""CarID"": [""C001"", ""C002"", ""C003"", ""C004"", ""C005"", ""C006""],
    ""Brand"": [""Toyota"", ""Honda"", ""Ford"", ""Toyota"", ""BMW"", ""Honda""],
    ""Model"": [""Camry"", ""Civic"", ""Focus"", ""Rav4"", ""X5"", ""Accord""],
    ""Year"": [2020, 2021, 2019, 2022, 2023, 2020],
    ""PriceUSD"": [25000, 22000, 18000, 30000, 60000, 24000],
    ""Mileage"": [30000, 20000, 45000, 15000, 5000, 35000]
}
df = pd.DataFrame(data)

# Filter for Toyota cars
toyota_cars = df[df[""...",10,"The generated code fully satisfies the task requirements with excellent correctness, code quality, and completeness. It correctly defines the DataFrame with identical data structure and content as the ground truth. The filtering logic (df[df[""Brand""] == ""Toyota""]) is technically sound and equivalent to the ground truth's boolean indexing approach. The average mileage calculation and printing are implemented accurately. The code is concise, clean, and follows proper Python/pandas conventions with appropriate imports and structure. While the ground truth includes an explicit empty DataFrame check, this is not critical for the task as the dataset explicitly contains Toyota cars. The generated code is functionally equivalent to the ground truth and meets all evaluation criteria perfectly.",gpt_4o,LLM_judge_config
M59,medium,Data Filtering,,"```python
import pandas as pd

data = {
    ""PokemonID"": [1, 2, 3, 4, 5, 6, 7, 8],
    ""Name"": [""Bulbasaur"", ""Ivysaur"", ""Venusaur"", ""Charmander"", ""Charmeleon"", ""Charizard"", ""Squirtle"", ""Wartortle""],
    ""Type1"": [""Grass"", ""Grass"", ""Grass"", ""Fire"", ""Fire"", ""Fire"", ""Water"", ""Water""],
    ""Type2"": [""Poison"", ""Poison"", ""Poison"", None, None, ""Flying"", None, None],
    ""HP"": [45, 60, 80, 39, 58, 78, 44, 59],
    ""Attack"": [49, 62, 82, 52, 64, 84, 48, 63],
    ""Defense"": [49, 63, 83, 43, 58, 78, 65, 80...",10,"The generated code fully satisfies all requirements. It correctly defines the DataFrame with the specified Pokemon stats, filters for Fire-type Pokemon using boolean indexing, and calculates and prints their average Attack stat. The code is concise, uses proper pandas syntax, and avoids unnecessary complexity. While the ground truth code includes additional error handling for empty DataFrames, the task did not explicitly require this, and the generated code works correctly for the provided data. The print statement is straightforward and meets the requirement to ""print their average Attack stat."" The code is well-structured and adheres to best practices for clarity and efficiency.",gpt_4o,LLM_judge_config
M6,medium,Data Visualization,titanic.csv,"```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

# Load data
df = pd.read_csv('titanic.csv')

# Preprocess data
df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 50, 80], labels=['Child', 'Teen', 'Young Adult', 'Adult', 'Senior'])
df['Survived'] = df['Survived'].map({0: 'Died', 1: 'Survived'})

# 1) Multi-panel figure showing survival rates by different demographic groups

fig1, axs = plt.subp...",5,"The generated code partially addresses the task but has several critical issues. 1) **Correctness**: It fails to handle missing data (Age/Fare) which is explicitly required, uses numeric Pclass instead of categorical labels, and has inconsistent AgeGroup bins. The heatmap uses numeric Pclass instead of the properly labeled 'Pclass_Cat' from the ground truth. The violin plot lacks proper categorization and the interactive plot misses custom color mapping. 2) **Code quality**: Proper imports are present but lacks np (needed for pd.cut). The dashboard uses a simple 2x2 grid instead of the flexible gridspec layout. 3) **Completeness**: The dashboard misses the KDE plot, text insights section, and fails to combine all required visualizations in a coherent storytelling format. The survival rate calculations in barplots use raw string mappings instead of preprocessed categorical variables. Key details like 'right=False' in pd.cut and 'category_orders' in Plotly are missing.",gpt_4o,LLM_judge_config
M60,medium,Data Filtering & Aggregation,,"```python
import pandas as pd

# Define the data
data = {
    ""BookID"": [""B001"", ""B002"", ""B003"", ""B004"", ""B005"", ""B006""],
    ""Title"": [""The Great Gatsby"", ""To Kill a Mockingbird"", ""1984"", ""Pride and Prejudice"", ""The Hobbit"", ""Animal Farm""],
    ""Author"": [""F. Scott Fitzgerald"", ""Harper Lee"", ""George Orwell"", ""Jane Austen"", ""J.R.R. Tolkien"", ""George Orwell""],
    ""Genre"": [""Classic"", ""Classic"", ""Dystopian"", ""Romance"", ""Fantasy"", ""Dystopian""],
    ""Stock"": [12, 8, 15, 7, 20, 10],
    ""Price"": [10...",8,"The generated code correctly defines the DataFrame, filters for ""Dystopian"" books, and calculates the average stock. It follows proper Python and pandas syntax, with clean structure and readable variable names. However, it lacks error handling for cases where no Dystopian books exist (e.g., `dystopian_books` being empty), which could lead to an AttributeError when calling `.mean()` on an empty DataFrame. While the task assumes the provided data is valid, including a check for empty results (as in the ground truth) improves robustness. The code also omits optional print statements for the original DataFrame, but this is not required by the task. Overall, it meets the core requirements but could be made more robust with minimal additional code.",gpt_4o,LLM_judge_config
M7,medium,Hypothesis Testing,water_potability.csv,"```python
import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import ttest_ind, chi2_contingency, shapiro
import warnings
warnings.filterwarnings(""ignore"")

# Load dataset
df = pd.read_csv(""water_potability.csv"")

# Drop rows with missing values
df.dropna(inplace=True)

# List of numerical features to analyze
features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate',
            'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']

alpha = 0.05

pr...",6,"The generated code addresses some key aspects of the task but lacks critical elements for robust statistical analysis. While it correctly performs t-tests, chi-square tests, and Shapiro-Wilk tests, it fails to handle missing values (instead of imputing, it drops rows, which could bias results). It also lacks proper error handling (e.g., checking for the CSV file's existence). The code does not include detailed result interpretations with statistical methodology (e.g., ""Reject the null hypothesis"" statements), which are required. Cohen's d calculation is present but lacks safeguards for edge cases (e.g., zero variance). The code does not check for sufficient sample sizes in t-tests, and the normality tests are limited to a predefined list of features rather than all numerical features. These omissions reduce its completeness and reliability compared to the ground truth.",gpt_4o,LLM_judge_config
M8,medium,Classification,water_potability.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_s...",5,"The generated code has several critical issues affecting correctness and completeness. 1) **Data Leakage**: Preprocessing (imputation and scaling) is applied before train-test split, violating best practices and potentially inflating evaluation metrics. 2) **Cross-Validation**: Uses `KFold` instead of `StratifiedKFold` and only evaluates accuracy, not all required metrics (precision, recall, F1, ROC-AUC). 3) **Feature Importance**: Only handles Random Forest and misses coefficients for Logistic Regression. 4) **ROC Curve**: Uses a rudimentary approach without the `RocCurveDisplay` utility, leading to less informative visualizations. 5) **Model Evaluation**: Lacks detailed comparisons (e.g., doesn't explicitly compare models based on all metrics or show cross-validation results per metric). The code also fails to properly retrain the best model for feature importance and uses inconsistent metric names (e.g., ""F1"" vs. ""F1-Score""). To improve, implement preprocessing after splitting, use stratified cross-validation, evaluate all metrics during CV, and handle feature importance for all models.",gpt_4o,LLM_judge_config
M9,medium,Feature Engineering,water_potability.csv,"```python
# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split

# Load dataset
df = pd.read_csv('water_potability.csv')

# Drop rows with missing values
df.dropna(inplace=True)

# Feature Engineering: Create new meaningful fe...",6,"The generated code partially addresses the task but lacks completeness and some critical aspects. It correctly creates engineered features (ratios, interactions, and polynomial features) and performs correlation analysis, but the feature engineering is less comprehensive than the ground truth (e.g., fewer ratios/interactions). The code drops missing values instead of imputing them, which is suboptimal for real-world data. Polynomial features are generated from all original columns (not a subset), risking excessive dimensionality. While it applies SelectKBest and RFE, it omits scaling (StandardScaler), which is important for fair comparison. Visualizations (heatmap, barplot, pairplot) are present but lack the detailed formatting and structure of the ground truth. The feature set comparison is minimal, missing nuanced analysis of overlaps and unique features. The code also includes a Venn diagram, but this is optional and not part of the core task. Overall, it meets basic requirements but fails to fully align with the depth and rigor of the ground truth implementation.",gpt_4o,LLM_judge_config
